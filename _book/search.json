[{"path":"index.html","id":"sobre","chapter":"Sobre","heading":"Sobre","text":"Aqui você encontra os exercícios e soluções livo Análises Ecológicas R.","code":""},{"path":"cap.-4---introdução-ao-r.html","id":"cap.-4---introdução-ao-r","chapter":"Cap. 4 - Introdução ao R","heading":"Cap. 4 - Introdução ao R","text":"4.1\nUse o R para verificar o resultado da operação 7 + 7 ÷ 7 + 7 x 7 - 7.Solução:4.2\nVerifique através R se 3x2³ é maior que 2x3².Solução:4.3\nCrie dois objetos (qualquer nome) com os valores 100 e 300. Multiplique esses objetos (função prod()) e atribuam ao objeto mult. Faça o logaritmo natural (função log()) objeto mult e atribuam ao objeto ln.Solução:4.4\nQuantos pacotes existem CRAN nesse momento? Execute essa combinação Console: nrow(available.packages(repos = \"http://cran.r-project.org\")).Solução:4.5\nInstale o pacote tidyverse CRAN.Solução:4.6\nEscolha números para jogar na mega-sena usando o R, nomeando o objeto como mega. Lembrando: são 6 valores de 1 60 e atribuam um objeto.Solução:4.7 Crie um fator chamado tr, com dois níveis (“cont” e “trat”) para descrever 100 locais de amostragem, 50 de cada tratamento. O fator deve ser dessa forma cont, cont, cont, ...., cont, trat, trat, ...., trat.Solução:4.8\nCrie uma matriz chamada ma, resultante da disposição de um vetor composto por 1000 valores aleatórios entre 0 e 10. matriz deve conter 100 linhas e ser disposta por colunas.Solução:4.9\nCrie um data frame chamado df, resultante da composição dos vetores:id: 1:50sp: sp01, sp02, ..., sp49, sp50ab: 50 valores aleatórios entre 0 5Solução:4.10\nCrie uma lista com os objetos criados anteriormente: mega, tr, ma e df.Solução:4.11\nSelecione os elementos ímpares objeto tr e atribua ao objeto tr_impar.Solução:4.12\nSelecione linhas com ids pares objeto df e atribua ao objeto df_ids_par.Solução:4.13\nFaça uma amostragem de 10 linhas objeto df e atribua ao objeto df_amos10.Solução:4.14\nAmostre 10 linhas objeto ma, mas utilizando linhas amostradas df_amos10 e atribua ao objeto ma_amos10.Solução:4.15\nUna colunas dos objetos df_amos10 e ma_amos10 e atribua ao objeto dados_amos10.Solução:","code":"\n7 + 7 / 7 + 7 * 7 - 7\n#> [1] 50\n3 * 2^3 > 2 * 3^2\n#> [1] TRUE\nobj1 <- 100\nobj2 <- 300\nmult <- prod(obj1, obj2)\nln <- log(obj1, obj2)\nnrow(available.packages(repos = \"http://cran.r-project.org\"))\n#> [1] 18916\ninstall.packages(\"tidyverse\", dependencies = TRUE)\nmega <- sample(x = 1:60, size = 6, replace = FALSE)\nmega\n#> [1] 11 10 30  1 46 52\ntr <- factor(c(rep(\"cont\", each = 50), rep(\"trat\", each = 50)))\ntr\n#>   [1] cont cont cont cont cont cont cont cont cont cont cont\n#>  [12] cont cont cont cont cont cont cont cont cont cont cont\n#>  [23] cont cont cont cont cont cont cont cont cont cont cont\n#>  [34] cont cont cont cont cont cont cont cont cont cont cont\n#>  [45] cont cont cont cont cont cont trat trat trat trat trat\n#>  [56] trat trat trat trat trat trat trat trat trat trat trat\n#>  [67] trat trat trat trat trat trat trat trat trat trat trat\n#>  [78] trat trat trat trat trat trat trat trat trat trat trat\n#>  [89] trat trat trat trat trat trat trat trat trat trat trat\n#> [100] trat\n#> Levels: cont trat\nma <- matrix(sample(0:10, 1000, rep = TRUE), nrow = 100, byrow = FALSE)\nma\n#>        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#>   [1,]    5    0    2    7    8    5    6    8    3    10\n#>   [2,]    9    7    4    3    1    6    2    4    2     6\n#>   [3,]    3    9    1    1    2    0    6    9    3     4\n#>   [4,]    7    6    2    6    4    3    6    6    3     3\n#>   [5,]    2    9    7   10    4    4    8    9    0     0\n#>   [6,]    2    5    4    8    7    2    1    9    3     7\n#>   [7,]    4    7    8    3    8    2    7    5    2     0\n#>   [8,]    6   10   10    7    9    8    3    3    3     4\n#>   [9,]    1    5    2    9    0    6    9    3    2     3\n#>  [10,]    3    6    7    7    5    5    0   10    2     7\n#>  [11,]    6    8    6    5    9   10    8    9    0    10\n#>  [12,]    4    6    4    5    1    2    8    9    8     1\n#>  [13,]    6    9    4    8    9    6    0    5    1     7\n#>  [14,]    7    6    5    6    1   10    1    8   10    10\n#>  [15,]    4   10    1    3    1    5    7    7    5     3\n#>  [16,]    9    1    2   10    7    2    9    3    4     6\n#>  [17,]    3   10    1    8    0    3    2    2    1    10\n#>  [18,]    1    6    1    7    1    8    0    1    5     4\n#>  [19,]    4    1    8   10    3    7    1    6    5     7\n#>  [20,]   10    3    8    0    8    2    0    4    8     2\n#>  [21,]    2    5   10    1    2   10    1    0   10     8\n#>  [22,]    3    5    7    3    4    3    2    0    9     8\n#>  [23,]    4    4    3    0    7    6    5    6    8     3\n#>  [24,]    1    9    1    1    2    2    2    8    4     4\n#>  [25,]   10    9    6    5    7    4   10    0    8     9\n#>  [26,]    1    6    1    3    9    6    7    3    0     5\n#>  [27,]    6    0    9    4   10    7    4   10    4     7\n#>  [28,]    1    7    5    3    4    8    8    2    0    10\n#>  [29,]    2    2    3    8    8    7    1    3    7     5\n#>  [30,]    6    2    1    8    4    1    8    1    8     2\n#>  [31,]    2    9    8    3    9    5    0    9    8     9\n#>  [32,]    0    6    6    5    1    2    6    9    9     4\n#>  [33,]    5    1   10    2   10    5    6    0    9     4\n#>  [34,]    8    1    3    1   10    2    2    9    5     2\n#>  [35,]   10   10    8    3    6    4    9    3    6     2\n#>  [36,]    7    9    0    3    5   10    5    5    8     7\n#>  [37,]    0    8    1    7    9    9    5    4    5     5\n#>  [38,]    5    4    7    4   10    1    4    9    9     2\n#>  [39,]    8    3    9    3    0    5    7    9    6     2\n#>  [40,]    9    6    8    3    4    2    1    1    1     2\n#>  [41,]    1    2    0    9    5    8    8    9    1    10\n#>  [42,]    6    5    7    4    9    3    5    2    0     7\n#>  [43,]    5    5    0    7    4    0   10    8    7     9\n#>  [44,]    8    3    9    1    4    5    0    2    1     8\n#>  [45,]    5    9    2    1    0    7    3   10    2     7\n#>  [46,]    7    7    4   10    0    2    9    7    6     3\n#>  [47,]   10   10    4    4    4    6    2    3    6     3\n#>  [48,]    3    0    5    3    9    3    2    2    6     1\n#>  [49,]    2   10    4    3    5    8    6    6    5     2\n#>  [50,]    2    8    6   10    3    1    3    7    6     6\n#>  [51,]    7    8    0    7    8   10    6    7    7     4\n#>  [52,]   10    2    0    3    0    3    2    1    1     7\n#>  [53,]   10    8   10    3    8    8    4    8    1     1\n#>  [54,]    7    8    4    1    5    3    2    9    7    10\n#>  [55,]    7    2    7    1    7    6    0   10    1     0\n#>  [56,]    4   10    9    2    6    3    2    4    7     5\n#>  [57,]    9    3    7    0   10    0    1    3    1     7\n#>  [58,]    2    3    4    3    8   10    4   10    6     6\n#>  [59,]    2    6    7    4    4    4    5    9    1     2\n#>  [60,]    6    0    5    1    8    8    7    7    0     5\n#>  [61,]    0    6    8    4   10    6    2    4    6     4\n#>  [62,]    7    7    2    0    9    9    3    2   10     1\n#>  [63,]    7   10    5    3    8    0    8    2    8     2\n#>  [64,]    7    0    7    1   10    5    6    7    3     6\n#>  [65,]    0    5    4    9    0    5    3    0   10     6\n#>  [66,]    5    5    7    0    7    2    7   10    1    10\n#>  [67,]    8    4    1    4   10    0    6    7    6    10\n#>  [68,]    9    3    9    5    4    2    4    8    1     4\n#>  [69,]    1    2    1    9    7    5    0    2    7     4\n#>  [70,]    7   10    4    6   10    0    2    1    9     3\n#>  [71,]    4    5    1    6    4    3    3    7   10     8\n#>  [72,]    5    1    0    6    9   10    0    3    1     5\n#>  [73,]    2    0    2    2    9    3    3    9    5     8\n#>  [74,]    8    7    3    6    7   10    2    6    8     3\n#>  [75,]   10    6    2    0    9    0    2    8    5     7\n#>  [76,]    0    3    7   10    5    3    8    9    5     2\n#>  [77,]    1    1    0    8    1    8    1    3    8     0\n#>  [78,]    9    5    9    2    3    3    9    9    4     7\n#>  [79,]    9    8    4    0    7    7    6    0    0     6\n#>  [80,]    1    5    2    3    2    5    6    8    5     2\n#>  [81,]    1    0    4    5    8    4    4   10    1     2\n#>  [82,]    7    3    5    2    0    4    6    1    0     7\n#>  [83,]    7    3    6    4    8    0    5    2    4     9\n#>  [84,]    4   10    7    5    6    1    7    5    3     0\n#>  [85,]    1    5    0    2    0    9    4    7   10     3\n#>  [86,]    8    9    0    7    8    7    6    1    3     3\n#>  [87,]    4    1    9    7    2    7    8    4    4     4\n#>  [88,]    2   10    2    8    0    1   10    9    3     6\n#>  [89,]    1    9    2    5    0    9    4    0    0     3\n#>  [90,]    3    8    9    7    9    7    2    1    9     1\n#>  [91,]    6    3    6    7    5    6    7    2    6     3\n#>  [92,]    8    9    6    5   10   10    4    4    4     1\n#>  [93,]    6    4    6    8    1    0    5    6    0     8\n#>  [94,]    8    6    8    0    6    7    6    0    3     6\n#>  [95,]    7    8    3   10    0    2    2    7    6     7\n#>  [96,]    7    9    7    4   10    8    3    5    5     4\n#>  [97,]    9    3    8    0   10   10    0    1    5     4\n#>  [98,]    4    0    5    6    5    8    0    8    7     0\n#>  [99,]    0   10   10    8    4    2    3    8    6     0\n#> [100,]    6    4    6    4    7    4    8    2    4     2\ndf <- data.frame(id = 1:50,\n                  sp = c(paste0(\"sp0\", 1:9), paste0(\"sp\", 10:50)),\n                  ab = sample(0:5, 50, rep = TRUE))\ndf\n#>    id   sp ab\n#> 1   1 sp01  4\n#> 2   2 sp02  2\n#> 3   3 sp03  2\n#> 4   4 sp04  1\n#> 5   5 sp05  4\n#> 6   6 sp06  3\n#> 7   7 sp07  3\n#> 8   8 sp08  5\n#> 9   9 sp09  2\n#> 10 10 sp10  0\n#> 11 11 sp11  1\n#> 12 12 sp12  5\n#> 13 13 sp13  3\n#> 14 14 sp14  3\n#> 15 15 sp15  2\n#> 16 16 sp16  4\n#> 17 17 sp17  0\n#> 18 18 sp18  1\n#> 19 19 sp19  4\n#> 20 20 sp20  0\n#> 21 21 sp21  0\n#> 22 22 sp22  1\n#> 23 23 sp23  4\n#> 24 24 sp24  5\n#> 25 25 sp25  4\n#> 26 26 sp26  2\n#> 27 27 sp27  4\n#> 28 28 sp28  0\n#> 29 29 sp29  4\n#> 30 30 sp30  1\n#> 31 31 sp31  1\n#> 32 32 sp32  4\n#> 33 33 sp33  3\n#> 34 34 sp34  0\n#> 35 35 sp35  5\n#> 36 36 sp36  5\n#> 37 37 sp37  5\n#> 38 38 sp38  2\n#> 39 39 sp39  1\n#> 40 40 sp40  2\n#> 41 41 sp41  2\n#> 42 42 sp42  0\n#> 43 43 sp43  0\n#> 44 44 sp44  3\n#> 45 45 sp45  2\n#> 46 46 sp46  1\n#> 47 47 sp47  4\n#> 48 48 sp48  2\n#> 49 49 sp49  4\n#> 50 50 sp50  4\nlis <- list(mega, tr, ma, df)\nlis\n#> [[1]]\n#> [1] 11 10 30  1 46 52\n#> \n#> [[2]]\n#>   [1] cont cont cont cont cont cont cont cont cont cont cont\n#>  [12] cont cont cont cont cont cont cont cont cont cont cont\n#>  [23] cont cont cont cont cont cont cont cont cont cont cont\n#>  [34] cont cont cont cont cont cont cont cont cont cont cont\n#>  [45] cont cont cont cont cont cont trat trat trat trat trat\n#>  [56] trat trat trat trat trat trat trat trat trat trat trat\n#>  [67] trat trat trat trat trat trat trat trat trat trat trat\n#>  [78] trat trat trat trat trat trat trat trat trat trat trat\n#>  [89] trat trat trat trat trat trat trat trat trat trat trat\n#> [100] trat\n#> Levels: cont trat\n#> \n#> [[3]]\n#>        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#>   [1,]    5    0    2    7    8    5    6    8    3    10\n#>   [2,]    9    7    4    3    1    6    2    4    2     6\n#>   [3,]    3    9    1    1    2    0    6    9    3     4\n#>   [4,]    7    6    2    6    4    3    6    6    3     3\n#>   [5,]    2    9    7   10    4    4    8    9    0     0\n#>   [6,]    2    5    4    8    7    2    1    9    3     7\n#>   [7,]    4    7    8    3    8    2    7    5    2     0\n#>   [8,]    6   10   10    7    9    8    3    3    3     4\n#>   [9,]    1    5    2    9    0    6    9    3    2     3\n#>  [10,]    3    6    7    7    5    5    0   10    2     7\n#>  [11,]    6    8    6    5    9   10    8    9    0    10\n#>  [12,]    4    6    4    5    1    2    8    9    8     1\n#>  [13,]    6    9    4    8    9    6    0    5    1     7\n#>  [14,]    7    6    5    6    1   10    1    8   10    10\n#>  [15,]    4   10    1    3    1    5    7    7    5     3\n#>  [16,]    9    1    2   10    7    2    9    3    4     6\n#>  [17,]    3   10    1    8    0    3    2    2    1    10\n#>  [18,]    1    6    1    7    1    8    0    1    5     4\n#>  [19,]    4    1    8   10    3    7    1    6    5     7\n#>  [20,]   10    3    8    0    8    2    0    4    8     2\n#>  [21,]    2    5   10    1    2   10    1    0   10     8\n#>  [22,]    3    5    7    3    4    3    2    0    9     8\n#>  [23,]    4    4    3    0    7    6    5    6    8     3\n#>  [24,]    1    9    1    1    2    2    2    8    4     4\n#>  [25,]   10    9    6    5    7    4   10    0    8     9\n#>  [26,]    1    6    1    3    9    6    7    3    0     5\n#>  [27,]    6    0    9    4   10    7    4   10    4     7\n#>  [28,]    1    7    5    3    4    8    8    2    0    10\n#>  [29,]    2    2    3    8    8    7    1    3    7     5\n#>  [30,]    6    2    1    8    4    1    8    1    8     2\n#>  [31,]    2    9    8    3    9    5    0    9    8     9\n#>  [32,]    0    6    6    5    1    2    6    9    9     4\n#>  [33,]    5    1   10    2   10    5    6    0    9     4\n#>  [34,]    8    1    3    1   10    2    2    9    5     2\n#>  [35,]   10   10    8    3    6    4    9    3    6     2\n#>  [36,]    7    9    0    3    5   10    5    5    8     7\n#>  [37,]    0    8    1    7    9    9    5    4    5     5\n#>  [38,]    5    4    7    4   10    1    4    9    9     2\n#>  [39,]    8    3    9    3    0    5    7    9    6     2\n#>  [40,]    9    6    8    3    4    2    1    1    1     2\n#>  [41,]    1    2    0    9    5    8    8    9    1    10\n#>  [42,]    6    5    7    4    9    3    5    2    0     7\n#>  [43,]    5    5    0    7    4    0   10    8    7     9\n#>  [44,]    8    3    9    1    4    5    0    2    1     8\n#>  [45,]    5    9    2    1    0    7    3   10    2     7\n#>  [46,]    7    7    4   10    0    2    9    7    6     3\n#>  [47,]   10   10    4    4    4    6    2    3    6     3\n#>  [48,]    3    0    5    3    9    3    2    2    6     1\n#>  [49,]    2   10    4    3    5    8    6    6    5     2\n#>  [50,]    2    8    6   10    3    1    3    7    6     6\n#>  [51,]    7    8    0    7    8   10    6    7    7     4\n#>  [52,]   10    2    0    3    0    3    2    1    1     7\n#>  [53,]   10    8   10    3    8    8    4    8    1     1\n#>  [54,]    7    8    4    1    5    3    2    9    7    10\n#>  [55,]    7    2    7    1    7    6    0   10    1     0\n#>  [56,]    4   10    9    2    6    3    2    4    7     5\n#>  [57,]    9    3    7    0   10    0    1    3    1     7\n#>  [58,]    2    3    4    3    8   10    4   10    6     6\n#>  [59,]    2    6    7    4    4    4    5    9    1     2\n#>  [60,]    6    0    5    1    8    8    7    7    0     5\n#>  [61,]    0    6    8    4   10    6    2    4    6     4\n#>  [62,]    7    7    2    0    9    9    3    2   10     1\n#>  [63,]    7   10    5    3    8    0    8    2    8     2\n#>  [64,]    7    0    7    1   10    5    6    7    3     6\n#>  [65,]    0    5    4    9    0    5    3    0   10     6\n#>  [66,]    5    5    7    0    7    2    7   10    1    10\n#>  [67,]    8    4    1    4   10    0    6    7    6    10\n#>  [68,]    9    3    9    5    4    2    4    8    1     4\n#>  [69,]    1    2    1    9    7    5    0    2    7     4\n#>  [70,]    7   10    4    6   10    0    2    1    9     3\n#>  [71,]    4    5    1    6    4    3    3    7   10     8\n#>  [72,]    5    1    0    6    9   10    0    3    1     5\n#>  [73,]    2    0    2    2    9    3    3    9    5     8\n#>  [74,]    8    7    3    6    7   10    2    6    8     3\n#>  [75,]   10    6    2    0    9    0    2    8    5     7\n#>  [76,]    0    3    7   10    5    3    8    9    5     2\n#>  [77,]    1    1    0    8    1    8    1    3    8     0\n#>  [78,]    9    5    9    2    3    3    9    9    4     7\n#>  [79,]    9    8    4    0    7    7    6    0    0     6\n#>  [80,]    1    5    2    3    2    5    6    8    5     2\n#>  [81,]    1    0    4    5    8    4    4   10    1     2\n#>  [82,]    7    3    5    2    0    4    6    1    0     7\n#>  [83,]    7    3    6    4    8    0    5    2    4     9\n#>  [84,]    4   10    7    5    6    1    7    5    3     0\n#>  [85,]    1    5    0    2    0    9    4    7   10     3\n#>  [86,]    8    9    0    7    8    7    6    1    3     3\n#>  [87,]    4    1    9    7    2    7    8    4    4     4\n#>  [88,]    2   10    2    8    0    1   10    9    3     6\n#>  [89,]    1    9    2    5    0    9    4    0    0     3\n#>  [90,]    3    8    9    7    9    7    2    1    9     1\n#>  [91,]    6    3    6    7    5    6    7    2    6     3\n#>  [92,]    8    9    6    5   10   10    4    4    4     1\n#>  [93,]    6    4    6    8    1    0    5    6    0     8\n#>  [94,]    8    6    8    0    6    7    6    0    3     6\n#>  [95,]    7    8    3   10    0    2    2    7    6     7\n#>  [96,]    7    9    7    4   10    8    3    5    5     4\n#>  [97,]    9    3    8    0   10   10    0    1    5     4\n#>  [98,]    4    0    5    6    5    8    0    8    7     0\n#>  [99,]    0   10   10    8    4    2    3    8    6     0\n#> [100,]    6    4    6    4    7    4    8    2    4     2\n#> \n#> [[4]]\n#>    id   sp ab\n#> 1   1 sp01  4\n#> 2   2 sp02  2\n#> 3   3 sp03  2\n#> 4   4 sp04  1\n#> 5   5 sp05  4\n#> 6   6 sp06  3\n#> 7   7 sp07  3\n#> 8   8 sp08  5\n#> 9   9 sp09  2\n#> 10 10 sp10  0\n#> 11 11 sp11  1\n#> 12 12 sp12  5\n#> 13 13 sp13  3\n#> 14 14 sp14  3\n#> 15 15 sp15  2\n#> 16 16 sp16  4\n#> 17 17 sp17  0\n#> 18 18 sp18  1\n#> 19 19 sp19  4\n#> 20 20 sp20  0\n#> 21 21 sp21  0\n#> 22 22 sp22  1\n#> 23 23 sp23  4\n#> 24 24 sp24  5\n#> 25 25 sp25  4\n#> 26 26 sp26  2\n#> 27 27 sp27  4\n#> 28 28 sp28  0\n#> 29 29 sp29  4\n#> 30 30 sp30  1\n#> 31 31 sp31  1\n#> 32 32 sp32  4\n#> 33 33 sp33  3\n#> 34 34 sp34  0\n#> 35 35 sp35  5\n#> 36 36 sp36  5\n#> 37 37 sp37  5\n#> 38 38 sp38  2\n#> 39 39 sp39  1\n#> 40 40 sp40  2\n#> 41 41 sp41  2\n#> 42 42 sp42  0\n#> 43 43 sp43  0\n#> 44 44 sp44  3\n#> 45 45 sp45  2\n#> 46 46 sp46  1\n#> 47 47 sp47  4\n#> 48 48 sp48  2\n#> 49 49 sp49  4\n#> 50 50 sp50  4\ntr_impar <- tr[seq(1, 99, 2)]\ntr_impar\n#>  [1] cont cont cont cont cont cont cont cont cont cont cont\n#> [12] cont cont cont cont cont cont cont cont cont cont cont\n#> [23] cont cont cont trat trat trat trat trat trat trat trat\n#> [34] trat trat trat trat trat trat trat trat trat trat trat\n#> [45] trat trat trat trat trat trat\n#> Levels: cont trat\ndf_ids_par <- df[seq(2, 100, 2), ]\ndf_ids_par\n#>       id   sp ab\n#> 2      2 sp02  2\n#> 4      4 sp04  1\n#> 6      6 sp06  3\n#> 8      8 sp08  5\n#> 10    10 sp10  0\n#> 12    12 sp12  5\n#> 14    14 sp14  3\n#> 16    16 sp16  4\n#> 18    18 sp18  1\n#> 20    20 sp20  0\n#> 22    22 sp22  1\n#> 24    24 sp24  5\n#> 26    26 sp26  2\n#> 28    28 sp28  0\n#> 30    30 sp30  1\n#> 32    32 sp32  4\n#> 34    34 sp34  0\n#> 36    36 sp36  5\n#> 38    38 sp38  2\n#> 40    40 sp40  2\n#> 42    42 sp42  0\n#> 44    44 sp44  3\n#> 46    46 sp46  1\n#> 48    48 sp48  2\n#> 50    50 sp50  4\n#> NA    NA <NA> NA\n#> NA.1  NA <NA> NA\n#> NA.2  NA <NA> NA\n#> NA.3  NA <NA> NA\n#> NA.4  NA <NA> NA\n#> NA.5  NA <NA> NA\n#> NA.6  NA <NA> NA\n#> NA.7  NA <NA> NA\n#> NA.8  NA <NA> NA\n#> NA.9  NA <NA> NA\n#> NA.10 NA <NA> NA\n#> NA.11 NA <NA> NA\n#> NA.12 NA <NA> NA\n#> NA.13 NA <NA> NA\n#> NA.14 NA <NA> NA\n#> NA.15 NA <NA> NA\n#> NA.16 NA <NA> NA\n#> NA.17 NA <NA> NA\n#> NA.18 NA <NA> NA\n#> NA.19 NA <NA> NA\n#> NA.20 NA <NA> NA\n#> NA.21 NA <NA> NA\n#> NA.22 NA <NA> NA\n#> NA.23 NA <NA> NA\n#> NA.24 NA <NA> NA\ndf_amos10 <- df[sample(nrow(df), 10), ]\ndf_amos10\n#>    id   sp ab\n#> 8   8 sp08  5\n#> 4   4 sp04  1\n#> 36 36 sp36  5\n#> 18 18 sp18  1\n#> 41 41 sp41  2\n#> 38 38 sp38  2\n#> 50 50 sp50  4\n#> 10 10 sp10  0\n#> 14 14 sp14  3\n#> 26 26 sp26  2\nma_amos10 <- ma[df_amos10$id, ]\nma_amos10\n#>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#>  [1,]    6   10   10    7    9    8    3    3    3     4\n#>  [2,]    7    6    2    6    4    3    6    6    3     3\n#>  [3,]    7    9    0    3    5   10    5    5    8     7\n#>  [4,]    1    6    1    7    1    8    0    1    5     4\n#>  [5,]    1    2    0    9    5    8    8    9    1    10\n#>  [6,]    5    4    7    4   10    1    4    9    9     2\n#>  [7,]    2    8    6   10    3    1    3    7    6     6\n#>  [8,]    3    6    7    7    5    5    0   10    2     7\n#>  [9,]    7    6    5    6    1   10    1    8   10    10\n#> [10,]    1    6    1    3    9    6    7    3    0     5\ndados_amos10 <- cbind(df_amos10, ma_amos10)\ndados_amos10\n#>    id   sp ab 1  2  3  4  5  6 7  8  9 10\n#> 8   8 sp08  5 6 10 10  7  9  8 3  3  3  4\n#> 4   4 sp04  1 7  6  2  6  4  3 6  6  3  3\n#> 36 36 sp36  5 7  9  0  3  5 10 5  5  8  7\n#> 18 18 sp18  1 1  6  1  7  1  8 0  1  5  4\n#> 41 41 sp41  2 1  2  0  9  5  8 8  9  1 10\n#> 38 38 sp38  2 5  4  7  4 10  1 4  9  9  2\n#> 50 50 sp50  4 2  8  6 10  3  1 3  7  6  6\n#> 10 10 sp10  0 3  6  7  7  5  5 0 10  2  7\n#> 14 14 sp14  3 7  6  5  6  1 10 1  8 10 10\n#> 26 26 sp26  2 1  6  1  3  9  6 7  3  0  5"},{"path":"cap.-5---tidyverse.html","id":"cap.-5---tidyverse","chapter":"Cap. 5 - Tidyverse","heading":"Cap. 5 - Tidyverse","text":"5.1\nReescreva operações abaixo utilizando pipes %>%.\n- log10(cumsum(1:100))\n- sum(sqrt(abs(rnorm(100))))\n- sum(sort(sample(1:10, 10000, rep = TRUE)))Solução:5.2\nUse função download.file() e unzip() para baixar e extrair o arquivo data paper de médios e grandes mamíferos: ATLANTIC MAMMALS. Em seguinda, importe para o R, usando função readr::read_csv().Solução:5.3\nUse função tibble::glimpse() para ter uma noção geral dos dados importados item anterior.Solução:5.4\nCompare os dados de penguins (palmerpenguins::penguins_raw e palmerpenguins::penguins). Monte uma série de funções dos pacotes tidyr e dplyr para limpar os dados e fazer com que o primeiro dado seja igual ao segundo.Solução:5.5\nUsando os dados de penguins (palmerpenguins::penguins), calcule correlação de Pearson entre comprimento e profundidade bico para cada espécie e para todas espécies. Compare os índices de correlação para exemplificar o Paradoxo de Simpsom.Solução:5.6\nOficialmente pandemia de COVID-19 começou Brasil com o primeiro caso dia 26 de fevereiro de 2020. Calcule quantos anos, meses e dias se passou desde então. Calcule também quanto tempo se passou até você ser vacinado.Solução:","code":"\nlibrary(tidyverse)\n\n1:100 %>% \n    cumsum() %>% \n    log10()\n#>   [1] 0.0000000 0.4771213 0.7781513 1.0000000 1.1760913\n#>   [6] 1.3222193 1.4471580 1.5563025 1.6532125 1.7403627\n#>  [11] 1.8195439 1.8920946 1.9590414 2.0211893 2.0791812\n#>  [16] 2.1335389 2.1846914 2.2329961 2.2787536 2.3222193\n#>  [21] 2.3636120 2.4031205 2.4409091 2.4771213 2.5118834\n#>  [26] 2.5453071 2.5774918 2.6085260 2.6384893 2.6674530\n#>  [31] 2.6954817 2.7226339 2.7489629 2.7745170 2.7993405\n#>  [36] 2.8234742 2.8469553 2.8698182 2.8920946 2.9138139\n#>  [41] 2.9350032 2.9556878 2.9758911 2.9956352 3.0149403\n#>  [46] 3.0338257 3.0523091 3.0704073 3.0881361 3.1055102\n#>  [51] 3.1225435 3.1392492 3.1556396 3.1717265 3.1875207\n#>  [56] 3.2030329 3.2182729 3.2332500 3.2479733 3.2624511\n#>  [61] 3.2766915 3.2907022 3.3044905 3.3180633 3.3314273\n#>  [66] 3.3445887 3.3575537 3.3703280 3.3829171 3.3953264\n#>  [71] 3.4075608 3.4196254 3.4315246 3.4432630 3.4548449\n#>  [76] 3.4662743 3.4775553 3.4886917 3.4996871 3.5105450\n#>  [81] 3.5212689 3.5318619 3.5423274 3.5526682 3.5628874\n#>  [86] 3.5729877 3.5829719 3.5928427 3.6026025 3.6122539\n#>  [91] 3.6217992 3.6312408 3.6405808 3.6498215 3.6589648\n#>  [96] 3.6680130 3.6769678 3.6858313 3.6946052 3.7032914\n\nrnorm(100) %>% \n    abs() %>% \n    sqrt() %>% \n    sum()\n#> [1] 82.55207\n\nsample(1:10, 10000, rep = TRUE) %>% \n    sort() %>% \n    sum()\n#> [1] 55176\nlibrary(tidyverse)\ndownload.file(url = \"https://esajournals.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fecy.2785&file=ecy2785-sup-0001-DataS1.zip\", \n              destfile = \"ecy2785-sup-0001-DataS1.zip\", mode = \"wb\")\n\nunzip(\"ecy2785-sup-0001-DataS1.zip\")\n\ndp_lm <- readr::read_csv(\"ATLANTIC_MAMMAL_MID_LARGE _assemblages_and_sites.csv\")\nlibrary(tidyverse)\ndplyr::glimpse(dp_lm)\n#> Rows: 4,680\n#> Columns: 40\n#> $ ID                     <chr> \"AML01\", \"AML01\", \"AML01\", …\n#> $ Reference_paper_number <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n#> $ Country                <chr> \"Brazil\", \"Brazil\", \"Brazil…\n#> $ State                  <chr> \"rio_grande_do_sul\", \"rio_g…\n#> $ Municipality           <chr> \"Sinimbu\", \"Sinimbu\", \"Sini…\n#> $ Study_location         <chr> \"Reserva Particular do Patr…\n#> $ Latitude               <dbl> -29.38333, -29.38333, -29.3…\n#> $ Longitude              <dbl> -52.53333, -52.53333, -52.5…\n#> $ Precision              <chr> \"not_precise\", \"not_precise…\n#> $ Size_ha                <chr> \"221\", \"221\", \"221\", \"221\",…\n#> $ Temperature            <chr> \"18\", \"18\", \"18\", \"18\", \"18…\n#> $ Altitude               <chr> \"150-650\", \"150-650\", \"150-…\n#> $ Annual_rainfall        <chr> NA, NA, NA, NA, NA, NA, NA,…\n#> $ Vegetation_type        <chr> \"Semideciduous forest\", \"Se…\n#> $ Protect_area           <chr> \"yes\", \"yes\", \"yes\", \"yes\",…\n#> $ Matrix                 <chr> NA, NA, NA, NA, NA, NA, NA,…\n#> $ Reference              <chr> \"Abreu-Junior, E.F. and Koh…\n#> $ Publication_year       <dbl> 2009, 2009, 2009, 2009, 200…\n#> $ Type_of_publication    <chr> \"Article\", \"Article\", \"Arti…\n#> $ Month_start            <chr> \"November\", \"November\", \"No…\n#> $ Year_start             <dbl> 2007, 2007, 2007, 2007, 200…\n#> $ Month_finish           <chr> \"April\", \"April\", \"April\", …\n#> $ Year_finish            <dbl> 2009, 2009, 2009, 2009, 200…\n#> $ Total_of_months        <dbl> 6, 6, 6, 6, 6, 6, 6, 6, 6, …\n#> $ Sampling_habitat       <chr> \"Interior\", \"Interior\", \"In…\n#> $ Effort                 <dbl> 109.00, 109.00, 109.00, 109…\n#> $ Effort_method          <chr> \"camera_days\", \"camera_days…\n#> $ Method                 <chr> \"mixed_method\", \"mixed_meth…\n#> $ Order                  <chr> \"Carnivora\", \"Rodentia\", \"C…\n#> $ Genus_on_paper         <chr> \"Cerdocyon\", \"Cuniculus\", \"…\n#> $ Species_name_on_paper  <chr> \"Cerdocyon thous\", \"Cunicul…\n#> $ Actual_species_Name    <chr> \"Cerdocyon thous\", \"Cunicul…\n#> $ Number_of_record       <chr> NA, NA, NA, NA, NA, NA, NA,…\n#> $ `Density(groups/km2)`  <dbl> NA, NA, NA, NA, NA, NA, NA,…\n#> $ `Density(ind/km2)`     <chr> NA, NA, NA, NA, NA, NA, NA,…\n#> $ `Density(ind/km10)`    <dbl> NA, NA, NA, NA, NA, NA, NA,…\n#> $ `Abundance(%)`         <dbl> NA, NA, NA, NA, NA, NA, NA,…\n#> $ Abudance_relative      <dbl> NA, NA, NA, NA, NA, NA, NA,…\n#> $ `Abundance(10/km)`     <dbl> NA, NA, NA, NA, NA, NA, NA,…\n#> $ Voucher_Specimens      <chr> NA, NA, NA, NA, NA, NA, NA,…\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\npenguins_raw\n#> # A tibble: 344 × 17\n#>    studyName `Sample Number` Species    Region Island Stage \n#>    <chr>               <dbl> <chr>      <chr>  <chr>  <chr> \n#>  1 PAL0708                 1 Adelie Pe… Anvers Torge… Adult…\n#>  2 PAL0708                 2 Adelie Pe… Anvers Torge… Adult…\n#>  3 PAL0708                 3 Adelie Pe… Anvers Torge… Adult…\n#>  4 PAL0708                 4 Adelie Pe… Anvers Torge… Adult…\n#>  5 PAL0708                 5 Adelie Pe… Anvers Torge… Adult…\n#>  6 PAL0708                 6 Adelie Pe… Anvers Torge… Adult…\n#>  7 PAL0708                 7 Adelie Pe… Anvers Torge… Adult…\n#>  8 PAL0708                 8 Adelie Pe… Anvers Torge… Adult…\n#>  9 PAL0708                 9 Adelie Pe… Anvers Torge… Adult…\n#> 10 PAL0708                10 Adelie Pe… Anvers Torge… Adult…\n#> # … with 334 more rows, and 11 more variables:\n#> #   Individual ID <chr>, Clutch Completion <chr>,\n#> #   Date Egg <date>, Culmen Length (mm) <dbl>,\n#> #   Culmen Depth (mm) <dbl>, Flipper Length (mm) <dbl>,\n#> #   Body Mass (g) <dbl>, Sex <chr>,\n#> #   Delta 15 N (o/oo) <dbl>, Delta 13 C (o/oo) <dbl>,\n#> #   Comments <chr>\npenguins\n#> # A tibble: 344 × 8\n#>    species island    bill_length_mm bill_depth_mm\n#>    <fct>   <fct>              <dbl>         <dbl>\n#>  1 Adelie  Torgersen           39.1          18.7\n#>  2 Adelie  Torgersen           39.5          17.4\n#>  3 Adelie  Torgersen           40.3          18  \n#>  4 Adelie  Torgersen           NA            NA  \n#>  5 Adelie  Torgersen           36.7          19.3\n#>  6 Adelie  Torgersen           39.3          20.6\n#>  7 Adelie  Torgersen           38.9          17.8\n#>  8 Adelie  Torgersen           39.2          19.6\n#>  9 Adelie  Torgersen           34.1          18.1\n#> 10 Adelie  Torgersen           42            20.2\n#> # … with 334 more rows, and 4 more variables:\n#> #   flipper_length_mm <int>, body_mass_g <int>, sex <fct>,\n#> #   year <int>\n\npenguins_raw %>% \n    dplyr::select(Species, Island, `Culmen Length (mm)`:Sex, `Date Egg`) %>% \n    dplyr::rename(species = Species,\n                  island = Island,\n                  bill_length_mm = `Culmen Length (mm)`,\n                  bill_depth_mm = `Culmen Depth (mm)`,\n                  flipper_length_mm = `Flipper Length (mm)`,\n                  body_mass_g = `Body Mass (g)`,\n                  sex = Sex,\n                  year = `Date Egg`) %>% \n    tidyr::separate(species, c(\"species\", NA, NA, NA, NA)) %>% \n    dplyr::mutate(sex = stringr::str_to_lower(sex),\n                  year = lubridate::year(year))\n#> # A tibble: 344 × 8\n#>    species island    bill_length_mm bill_depth_mm\n#>    <chr>   <chr>              <dbl>         <dbl>\n#>  1 Adelie  Torgersen           39.1          18.7\n#>  2 Adelie  Torgersen           39.5          17.4\n#>  3 Adelie  Torgersen           40.3          18  \n#>  4 Adelie  Torgersen           NA            NA  \n#>  5 Adelie  Torgersen           36.7          19.3\n#>  6 Adelie  Torgersen           39.3          20.6\n#>  7 Adelie  Torgersen           38.9          17.8\n#>  8 Adelie  Torgersen           39.2          19.6\n#>  9 Adelie  Torgersen           34.1          18.1\n#> 10 Adelie  Torgersen           42            20.2\n#> # … with 334 more rows, and 4 more variables:\n#> #   flipper_length_mm <dbl>, body_mass_g <dbl>, sex <chr>,\n#> #   year <dbl>\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\ncor(penguins$bill_length_mm, penguins$bill_depth_mm, use = \"na.or.complete\")\n#> [1] -0.2350529\n\npenguins %>%\n    dplyr::group_split(species) %>% \n    purrr::map(~cor(.x$bill_length_mm, .x$bill_depth_mm, use = \"na.or.complete\"))\n#> [[1]]\n#> [1] 0.3914917\n#> \n#> [[2]]\n#> [1] 0.6535362\n#> \n#> [[3]]\n#> [1] 0.6433839\ncovid_inicio_br <- lubridate::dmy(\"26-02-2020\")\nvacina <- lubridate::dmy(\"20-07-2021\")\n\nintervalo_covid <- lubridate::interval(covid_inicio_br, lubridate::today())\nintervalo_vacina <- lubridate::interval(covid_inicio_br, vacina)\n\nlubridate::as.period(intervalo_covid)\n#> [1] \"1y 11m 18d 0H 0M 0S\"\nlubridate::as.period(intervalo_vacina)\n#> [1] \"1y 4m 24d 0H 0M 0S\""},{"path":"cap.-6---visualização-de-dados.html","id":"cap.-6---visualização-de-dados","chapter":"Cap. 6 - Visualização de dados","heading":"Cap. 6 - Visualização de dados","text":"6.1\nUtilizando o banco de dados penguins compare o comprimento bico entre diferentes espécies de penguins. Utilize um gráfico de caixa (boxplot) para ilustrar variação intraespecífica e possíveis outliers nos dados. Para melhorar o seu gráfico, lembre-se de nomear os dois eixos corretamente, definir um tema e posicionar legenda.Solução:¨6.2\nUtilizando o banco de dados penguins faça um histograma com distribuição da massa corporal para cada uma das espécies. Utilize uma cor de preenchimento para cada espécie.Solução:¨6.3\nUtilizando o banco de dados penguins, faça três gráficos com o mesmo eixo Y e eixo X. Coloque o comprimento das nadadeiras eixo Y e espécies de pinguins eixo X. primeiro gráfico, utilize o geom_jitter() para plotar os dados brutos. segundo gráfico, utilize o geom_violin() para mostrar distribuição de densidade dos dados. terceiro gráfico, utilize o geom_boxplot() para destacar mediana e os quartis.Solução:¨6.4\nSe você conseguiu resolver o exercício 6.3, agora dê um passo mais e compare os três gráficos lado lado utilizando função grid.arrange(). Lembre-se de colocar um título informativo em cada um dos gráficos antes de juntá-los em uma prancha única. Ao comparar os 3 tipos de gráficos, qual você considera mais informativo? Experimente combinar mais de um “geom” (camadas) e produzir gráficos ainda mais interessantes.Solução:¨Agora misturando camadas.6.5\nUtilize o banco de dados ecodados::anova_dois_fatores para construir um gráfico de barras com média e o erro padrão Tempo (Tempo para eliminar droga corpo) eixo Y em função da variável Pessoas (XX, ou XY) e Idade (jovem ou idoso). Antes de fazer o gráfico leia com atenção descrição mesmo através comando ?ecodados::anova_dois_fatores. Uma dica, utilize fill dentro aes para representar um dos fatores (ex. Pessoas). O outro fator você pode representar eixo X. Veja se consegue, se não conseguir pode olhar cola com solução para aprender como é feito. Outra dica, pesquise sobre função stat_summary() ela irá te ajudar calcular média e o erro padrão dentro comando que gera o gráfico.Solução:¨Versão 1: calculando média e o erro padrão dentro próprio gráfico.Versão 2: calculando média e o erro padrão antes de produzir o gráfico.Agora use esse banco de dados para plotar média e o erro padrão.6.6\nUtilize o banco de dados penguins para criar um gráfico de dispersão entre o tamanho da nadadeira (eixo Y) e massa corporal (eixo X). Utilize o argumento fill para ilustrar com cores diferenças entre os sexos e utilize função facte_grid() para criar um gráfico separado para cada espécie de pinguim. Se você não conhece essa função, dê uma olhada help ?facet_grid. Você também pode utilizar função drop_na() para excluir os dados faltantes da coluna sexo.","code":"\n\n# Carregando pacotes necesários\nlibrary(tidyverse)\nlibrary(ecodados)\n\n# Dados\npenguins <- palmerpenguins::penguins\n\n# Edição dos nomes das colunas para português \n# names(penguins)\ncolnames(penguins) <- c(\"especies\", \"ilha\", \"comprimento_bico\", \n                        \"profundidade_bico\", \"comprimento_nadadeira\", \n                        \"massa_corporal\", \"sexo\", \"ano\")\n\n# Gráfico: Boxplot do tamanho do bico entre as diferentes espécies\nggplot(penguins, aes(y = comprimento_bico, x = especies, fill = especies)) +\n  geom_boxplot() +\n  theme_bw(base_size = 16) +\n  theme(\n    legend.position = \"top\"\n  ) +\n  labs(fill = \"Espécies\",\n       x = \"Espécies\", y = \"Comprimento do bico (mm)\")\nggplot(penguins, aes(x = massa_corporal, fill = especies)) +\n  geom_histogram(alpha = .5,  position = position_dodge()) +\n  theme_bw(base_size = 16) +\n  labs(x = \"Massa corporal (g)\",\n       y = \"Frequência\",\n       fill = \"Espécie\")\n# Gráfico de jitter com dados brutos\npjitter <- ggplot(penguins, aes(y = comprimento_nadadeira, x = especies )) +\n  geom_jitter()\npjitter\n\n# Gráfico violin com a densidade dos dados\npviolin <- ggplot(penguins, aes(y = comprimento_nadadeira, x = especies )) +\n  geom_violin()\npviolin\n\n# Gráfico de caixa com a media e os quartis\npcaixa  <- ggplot(penguins, aes(y = comprimento_nadadeira, x = especies )) +\n  geom_boxplot()\npcaixa\n# colocando um título em cada gráfico\npjitter <- pjitter + labs(title = \"Plot com jitter\")\npviolin <- pviolin + labs(title = \"Plot com violin\")\npcaixa  <- pcaixa + labs(title = \"Plot com boxplot\")\n\n# juntando os 3 gráficos em um só\n# Carregando o pacote gridExtra\nlibrary(gridExtra)\ngrid.arrange(pjitter, pviolin, pcaixa, ncol = 3)\n# Misturando geoms\nggplot(penguins, aes(y = comprimento_nadadeira, x = especies )) +\n  geom_jitter(size = .5, width = .2, aes(color = especies)) +\n  geom_boxplot(aes(fill = especies), alpha = .2, width = .2) +\n  geom_violin(fill = \"gray\", alpha = .1) +\n  theme_classic(base_size = 16) +\n  theme(legend.position = \"none\") +\n  labs(y = \"Comprimento da nadadeira (mm)\",\n       x = \"Espécie de pinguim\")\n# entenda o banco de dados primeiro\n?ecodados::anova_dois_fatores\nggplot(anova_dois_fatores, aes(y = Tempo, x = Idade, fill = Pessoas)) +\n  geom_point(position = position_dodge(width = .9), size = .5) +\n  stat_summary(fun = mean, geom = \"bar\", position = position_dodge(width = .9), alpha = .75) +\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", position = position_dodge(width = .9), \n               width = .2) +\n  scale_fill_manual(values = c(\"steelblue\", \"orange\")) +\n  theme_bw(base_size = 16) +\n  labs(y = \"Tempo (dias após administração)\",\n       x = \"Grupo etário\")\n# Calcular o desvio padrão \nanova_media <- anova_dois_fatores %>% \n    dplyr::group_by(Idade, Pessoas ) %>% \n    dplyr::summarise(media = mean(Tempo, na.rm = TRUE),\n                     desvio = sd(Tempo, na.rm = TRUE))\n#Veja como ficou \nhead(anova_media)\n#> # A tibble: 4 × 4\n#> # Groups:   Idade [2]\n#>   Idade Pessoas media desvio\n#>   <chr> <chr>   <dbl>  <dbl>\n#> 1 Idoso XX       30.9   2.01\n#> 2 Idoso XY       40.1   2.04\n#> 3 Jovem XX       18.7   2.14\n#> 4 Jovem XY       26.5   1.80\n# Gráfico de barras com desvio padrão\nggplot(data = anova_media, aes(y = media, x = Idade, fill = Pessoas)) +\n    geom_bar(stat = \"identity\", alpha = .75, position = position_dodge()) +\n    geom_errorbar(aes(ymin = media - desvio, ymax = media + desvio), \n                  width = .1, position = position_dodge(width = .9)) +\n  scale_fill_manual(values = c(\"steelblue\", \"orange\")) +\n  theme_bw(base_size = 16) +\n  labs(y = \"Tempo (dias após administração)\",\n       x = \"Grupo etário\")\n# primeiro vamos traduizir a coluna sexo para o português\npenguins$sexo <- fct_recode(penguins$sexo, masculino = \"male\", feminino = \"female\")\n\nggplot(penguins %>% drop_na(sexo), aes(y = comprimento_nadadeira, x = massa_corporal, \n                                       color = sexo, fill = sexo)) +\n  geom_point(size = .4) +\n  geom_smooth(method = lm) +\n  facet_grid(~especies) +\n  scale_color_manual(values = c(\"steelblue\", \"orange\"), aesthetics = c(\"fill\", \"color\")) +\n  theme_classic() +\n  labs(\n    y = \"Comprimento da nadadeira (mm)\",\n    x = \"Massa corporal (g)\"\n  ) "},{"path":"cap.-7---modelos-lineares.html","id":"cap.-7---modelos-lineares","chapter":"Cap. 7 - Modelos lineares","heading":"Cap. 7 - Modelos lineares","text":"7.1\nAvalie se os indivíduos machos de uma espécie de aranha são maiores que fêmeas. Qual sua interpretação sobre o dimorfismo sexual nesta espécie? Faça um gráfico boxplot usando também função geom_jitter.Use os dados Cap7_exercicio1 disponível pacote ecodados.Solução:7.2\nAvalie se o número de polinizadores visitando uma determinada espécie de planta é dependente da presença ou ausência de predadores. mesma planta, em tempos diferentes, foi utilizada como unidade amostral para os tratamentos com e sem predadores. Qual sua interpretação sobre os resultados? Faça um gráfico boxplot ligando os resultados da mesma planta com e sem presença predador.Use os dados Cap7_exercicio2 disponível pacote ecodados.Solução:7.3\nAvalie se existe correlação entre o número de filhotes nos ninhos de uma espécie de ave com o tamanho fragmento florestal. Qual sua interpretação dos resultados? Faça um gráfico mostrando relação entre variáveis. Use os dados Cap7_exercicio3 disponível pacote ecodados.Solução:7.4\nAvalie se relação entre o tamanho da área de diferentes ilhas e riqueza de espécies de lagartos. Qual sua interpretação dos resultados? Faça um gráfico mostrando relação predita pelo modelo.Use os dados Cap7_exercicio4 disponível pacote ecodados.Solução:7.5\nAvalie se existe relação entre abundância de uma espécie de roedor com o tamanho da área dos fragmentos florestais e/ou altitude. Faça uma regressão múltipla. Em seguida, crie diferentes modelos e selecione o mais parcimonioso com base valores teste de Likelihood-ratio test (LRT) e AIC. Qual sua interpretação? Use os dados Cap7_exercicio5 disponível pacote ecodados.Solução:7.6\nAvalie se o local que machos territoriais ocupam (pasto, cana, floresta) influência peso dos indivíduos. Qual sua interpretação dos resultados? Faça um gráfico com os resultados. Use os dados Cap7_exercicio6 disponível pacote ecodados.Solução:7.7\nAvalie se abundância de formigas está relacionada com o fato das domácias estarem abertas ou fechadas e com idade das domácias. Verifique interação entre os fatores. Qual sua interpretação dos resultados? Faça um gráfico com os resultados. Use os dados Cap7_exercicio7 disponível pacote ecodados.Solução:7.8\nAvalie se o número de parasitas está relacionado com o tamanho corporal de fêmeas de uma espécie de ave. Além disso, use idade das aves como uma co-variável explicando o número de parasitas. Qual sua interpretação dos resultados? Faça um gráfico com os resultados. Use os dados Cap7_exercicio8 disponível pacote ecodados.Solução:7.9\nAvalie se presença ou ausência de predadores afeta riqueza de macroinvertebrados em 10 lagos. Os tratamentos dos predadores foram realizados nos mesmos lagos. Qual sua interpretação dos resultados? Faça um gráfico com os resultados.Use os dados Cap7_exercicio9 disponível pacote ecodados.Solução:7.10\nAvalie se precipitação anual afeta riqueza de espécies de anuros em 44 localidades na Mata Atlântica. Use coordenadas geográficas para controlar o efeito da autocorrelação espacial. Qual sua interpretação dos resultados das análises com e sem levar em consideração autocorrelação espacial? Use os dados anuros_ambientais disponível pacote ecodados.Solução:","code":"\n# Pacotes necessários\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(lmtest)\nlibrary(bbmle)\nlibrary(car)\nlibrary(ggforce)\nlibrary(sjPlot)\nlibrary(nlme)\nlibrary(dplyr)\n# Carregar dados do pacote ecodados\nexercicio_1 <- ecodados::Cap7_exercicio1\n\n# Verificar as premissas do teste\nresiduos_exercicio1 <- lm(Tamanho ~ Sexo, data = exercicio_1)\n\n# Teste da normalidade dos resíduos\nshapiro.test(residuals(residuos_exercicio1))\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  residuals(residuos_exercicio1)\n#> W = 0.96586, p-value = 0.4328\n\n# Teste da Homogeneidade da variância dos resíduos\n\nleveneTest(Tamanho ~ Sexo, data = exercicio_1)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>       Df F value Pr(>F)\n#> group  1  2.0072 0.1676\n#>       28\n\n## Análise Teste T \nt.test(Tamanho ~ Sexo, data = exercicio_1, var.equal = TRUE)\n#> \n#>  Two Sample t-test\n#> \n#> data:  Tamanho by Sexo\n#> t = 2.2756, df = 28, p-value = 0.03072\n#> alternative hypothesis: true difference in means between group f and group m is not equal to 0\n#> 95 percent confidence interval:\n#>  0.2356113 4.4843887\n#> sample estimates:\n#> mean in group f mean in group m \n#>           10.08            7.72\n\n## Gráfico\nggplot(data = exercicio_1, aes(x = Sexo, y = Tamanho)) +\n  geom_boxplot(width = .5, show.legend = FALSE) +\n  theme_bw(base_size = 14) +\n  geom_jitter(size = 4, width = 0.1) +\n  scale_x_discrete(labels=c(\"Fêmeas\",\"Machos\")) +\n  labs(title = \"Dimorfismo sexual\", x = \"Sexo\", y = \"Tamanho (mm)\")\n\n# Carregar a planilha com os dados\nexercicio_2 <- ecodados::Cap7_exercicio2\n\n## Análise Teste T Pareado\nt.test(Polinizadores ~ Predadores, paired = TRUE, data = exercicio_2)\n#> \n#>  Paired t-test\n#> \n#> data:  Polinizadores by Predadores\n#> t = 2.843, df = 19, p-value = 0.0104\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  0.4088952 2.6911048\n#> sample estimates:\n#> mean of the differences \n#>                    1.55\n\n## Gráfico\nggpaired(exercicio_2, x = \"Predadores\", y = \"Polinizadores\",\n         color = \"Predadores\", line.color = \"gray\", line.size = 0.8, \n         palette = c(\"darkorange\", \"cyan4\"), width = 0.5, \n         point.size = 4, xlab = \"Predadores\", \n         ylab = \"Número de polinizadores visitando a planta\",\n         legend = \"none\") \n# Carregar a planilha com os dados\nexercicio_3 <- ecodados::Cap7_exercicio3\n\n## Análise correlação de Pearson\ncor.test(~ Filhotes + Fragmentos, data = exercicio_3, method = \"pearson\")\n#> \n#>  Pearson's product-moment correlation\n#> \n#> data:  Filhotes and Fragmentos\n#> t = -0.65396, df = 33, p-value = 0.5177\n#> alternative hypothesis: true correlation is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.4301428  0.2287595\n#> sample estimates:\n#>        cor \n#> -0.1131098\n\n## Gráfico\nggplot(data = exercicio_3, aes(x = Fragmentos, y = Filhotes)) + \n  labs(x = \"Tamanho dos fragmentos (ha)\", y = \"Número de filhotes\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  theme_bw(base_size = 16)\n# Carregar a planilha com os dados\nexercicio_4 <- ecodados::Cap7_exercicio4\n\n## Análise Regressão Simples\nmodelo_regressao <- lm(Riqueza ~ Area_ilhas, data = exercicio_4)\n\n## Análise das premissas\nplot_grid(plot_model(modelo_regressao , type = \"diag\"))\n\n\n## Olhar os resultados\nsummary(modelo_regressao)\n#> \n#> Call:\n#> lm(formula = Riqueza ~ Area_ilhas, data = exercicio_4)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -2.8077 -0.9996 -0.2656  0.9026  2.5195 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)   3.8398     1.2816   2.996  0.00453 ** \n#> Area_ilhas    0.2879     0.0143  20.133  < 2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.375 on 43 degrees of freedom\n#> Multiple R-squared:  0.9041, Adjusted R-squared:  0.9019 \n#> F-statistic: 405.3 on 1 and 43 DF,  p-value: < 2.2e-16\n\n## Gráfico\nggplot(data = exercicio_4, aes(x = Area_ilhas, y = Riqueza)) + \n  labs(x = \"Tamanho das ilhas (km2)\", y = \"Riqueza de espécies de lagartos\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)\n# Carregar a planilha com os dados\nexercicio_5 <- ecodados::Cap7_exercicio5\n\n## Análise Regressão Múltipla\nmodelo_regressao_mult <- lm(Abundancia ~ Area_fragmento*Altitude, data = exercicio_5)\n\n## Multicolinearidae\nvif(modelo_regressao_mult)\n#>          Area_fragmento                Altitude \n#>                5.403688                1.786589 \n#> Area_fragmento:Altitude \n#>                6.890149\n\n## Análise das premissas\nplot_grid(plot_model(modelo_regressao , type = \"diag\"))\n\n\n## Olhar os resultados\nsummary(modelo_regressao_mult)\n#> \n#> Call:\n#> lm(formula = Abundancia ~ Area_fragmento * Altitude, data = exercicio_5)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -10.4180  -1.3524  -0.2711   1.1783  12.5283 \n#> \n#> Coefficients:\n#>                           Estimate Std. Error t value\n#> (Intercept)              5.747e+01  8.549e-01  67.230\n#> Area_fragmento          -3.337e-03  3.245e-03  -1.028\n#> Altitude                -5.451e-03  4.859e-04 -11.218\n#> Area_fragmento:Altitude  1.344e-06  1.471e-06   0.914\n#>                         Pr(>|t|)    \n#> (Intercept)              < 2e-16 ***\n#> Area_fragmento             0.308    \n#> Altitude                1.69e-15 ***\n#> Area_fragmento:Altitude    0.365    \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 2.99 on 52 degrees of freedom\n#> Multiple R-squared:  0.7986, Adjusted R-squared:  0.787 \n#> F-statistic: 68.73 on 3 and 52 DF,  p-value: < 2.2e-16\n\n\n## Vamos retirar a interação\nmodelo_regressao_mult_sem_interacao <- lm(Abundancia ~ Area_fragmento + Altitude, data = exercicio_5)\n\n## Likelihood-ratio test (LRT)\nlrtest(modelo_regressao_mult, modelo_regressao_mult_sem_interacao)\n#> Likelihood ratio test\n#> \n#> Model 1: Abundancia ~ Area_fragmento * Altitude\n#> Model 2: Abundancia ~ Area_fragmento + Altitude\n#>   #Df  LogLik Df  Chisq Pr(>Chisq)\n#> 1   5 -138.71                     \n#> 2   4 -139.16 -1 0.8917      0.345\n\n## Vamos verificar o modelo só com a altitude \nmodelo_regressao_mult_sem_fragmento <- lm(Abundancia ~ Altitude, data = exercicio_5)\n\nlrtest(modelo_regressao_mult_sem_interacao, modelo_regressao_mult_sem_fragmento)\n#> Likelihood ratio test\n#> \n#> Model 1: Abundancia ~ Area_fragmento + Altitude\n#> Model 2: Abundancia ~ Altitude\n#>   #Df  LogLik Df  Chisq Pr(>Chisq)\n#> 1   4 -139.16                     \n#> 2   3 -139.28 -1 0.2364     0.6268\n\n## Vamos verificar o modelo só com o intercepto\nmodelo_regressao_mult_nulo <- lm(Abundancia ~ 1, data = exercicio_5)\n\nlrtest(modelo_regressao_mult_sem_fragmento, modelo_regressao_mult_nulo)\n#> Likelihood ratio test\n#> \n#> Model 1: Abundancia ~ Altitude\n#> Model 2: Abundancia ~ 1\n#>   #Df  LogLik Df  Chisq Pr(>Chisq)    \n#> 1   3 -139.28                         \n#> 2   2 -183.58 -1 88.611  < 2.2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Outra alternativa é usar o AIC para seleção dos modelos\n\n## modelo só com a área do fragmento\nmodelo_regressao_mult_sem_altitude <- lm(Abundancia ~ Area_fragmento, data = exercicio_5)\n\nAICc <- ICtab(modelo_regressao_mult, modelo_regressao_mult_sem_interacao, \n              modelo_regressao_mult_sem_fragmento,modelo_regressao_mult_nulo, \n              modelo_regressao_mult_sem_altitude,\n              type = c(\"AIC\"), weights = TRUE, \n              delta = TRUE, sort = TRUE)\nAICc\n#>                                     dAIC df weight\n#> modelo_regressao_mult_sem_fragmento  0.0 3  0.61  \n#> modelo_regressao_mult_sem_interacao  1.8 4  0.25  \n#> modelo_regressao_mult                2.9 5  0.14  \n#> modelo_regressao_mult_sem_altitude  85.6 3  <0.001\n#> modelo_regressao_mult_nulo          86.6 2  <0.001\n\n## Gráfico\nggplot(data = exercicio_5, aes(x = Altitude, y = Abundancia)) + \n  labs(x = \"Altitude (m)\", y = \"Abundância da espécie\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)\n# Carregar a planilha com os dados\nexercicio_6 <- ecodados::Cap7_exercicio6\n\n## Análise anova um fator\nmodelo_aov <- aov(Peso ~ Local, data = exercicio_6)\n\n## Normalidade \nshapiro.test(residuals(modelo_aov))\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  residuals(modelo_aov)\n#> W = 0.95361, p-value = 0.211\n\n## Homogeneidade da variância\nbartlett.test(Peso ~ Local, data = exercicio_6)\n#> \n#>  Bartlett test of homogeneity of variances\n#> \n#> data:  Peso by Local\n#> Bartlett's K-squared = 0.06087, df = 2, p-value =\n#> 0.97\n\n## Olhar os resultados\nanova(modelo_aov)\n#> Analysis of Variance Table\n#> \n#> Response: Peso\n#>           Df  Sum Sq Mean Sq F value    Pr(>F)    \n#> Local      2 20.0536 10.0268  248.47 < 2.2e-16 ***\n#> Residuals 27  1.0896  0.0404                      \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Diferenças entre os tratamentos\nTukeyHSD(modelo_aov)\n#>   Tukey multiple comparisons of means\n#>     95% family-wise confidence level\n#> \n#> Fit: aov(formula = Peso ~ Local, data = exercicio_6)\n#> \n#> $Local\n#>                      diff        lwr        upr p adj\n#> Floresta-Cana      1.1125  0.8897525  1.3352475     0\n#> Pastagem-Cana     -0.8859 -1.1086475 -0.6631525     0\n#> Pastagem-Floresta -1.9984 -2.2211475 -1.7756525     0\n\n\n## Gráfico\nggplot(data = exercicio_6, \n       aes(x = Local, y = Peso)) + \n  geom_boxplot(width = .5, show.legend = FALSE) +\n  geom_jitter(size = 4, width = 0.1) +\n  geom_text(x = 1, y = 17.5, label = \"a\", color = \"black\", size = 5) +\n  geom_text(x = 2, y = 18.5, label = \"b\", color = \"black\", size = 5) +\n  geom_text(x = 3, y = 16.5, label = \"c\", color = \"black\", size = 5) +\n  ylim(16, 18.5) +\n  theme_bw(base_size = 16) +\n  labs(x = \"Local\", y = \"Peso (g)\")\n# Carregar a planilha com os dados\nexercicio_7 <- ecodados::Cap7_exercicio7\n\n## Análise anova dois fatores\nmodelo_aov_2 <- aov(Abundancia ~ Domacea * Idade, data = exercicio_7)\n\n\n## Olhar os resultados\nanova(modelo_aov_2)\n#> Analysis of Variance Table\n#> \n#> Response: Abundancia\n#>               Df  Sum Sq Mean Sq F value    Pr(>F)    \n#> Domacea        1  931.22  931.22  32.993 1.528e-06 ***\n#> Idade          1  555.02  555.02  19.664 8.334e-05 ***\n#> Domacea:Idade  1  455.63  455.63  16.143 0.0002862 ***\n#> Residuals     36 1016.10   28.22                      \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Gráfico\nggplot(data = exercicio_7, \n       aes(y = Abundancia, x = Domacea, color = Idade)) + \n  geom_boxplot() +\n  stat_summary(fun = mean, geom =\"point\", aes(group = Idade, x = Domacea), \n               color = \"black\", position = position_dodge(0.7), size  = 4) +\n  geom_link(aes(x = 0.85, y = 27, xend = 1.8, yend = 24), color = \"darkorange\", \n            lwd  = 1.3, linetype = 2) + \n  geom_link(aes(x = 1.17, y = 26.5, xend = 2.15, yend = 10), color = \"cyan4\", \n            lwd  = 1.3, linetype = 2) + \n  labs(x = \"Condição da domácea\", \n       y = \"Abundância de formigas\") +\n  theme_bw(base_size = 16)\n# Carregar a planilha com os dados\nexercicio_8 <- ecodados::Cap7_exercicio8\n\n## Análise ancova\nmodelo_ancova <- lm(Parasitas ~ Femeas * Idade, data = exercicio_8)\n\n## Verificar as premissas\nplot_grid(plot_model(modelo_ancova, type = \"diag\"))\n\n## Olhar os resultados\nanova(modelo_ancova)\n#> Analysis of Variance Table\n#> \n#> Response: Parasitas\n#>              Df  Sum Sq Mean Sq F value  Pr(>F)  \n#> Femeas        2 111.577  55.789  3.2153 0.06885 .\n#> Idade         1 113.527 113.527  6.5431 0.02185 *\n#> Femeas:Idade  2  10.866   5.433  0.3131 0.73582  \n#> Residuals    15 260.261  17.351                  \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Criando modelo sem interação\nmodelo_ancova2 <- lm(Parasitas ~ Femeas + Idade, data = exercicio_8)\n\n## Likelihood-ratio test\nlrtest(modelo_ancova, modelo_ancova2)\n#> Likelihood ratio test\n#> \n#> Model 1: Parasitas ~ Femeas * Idade\n#> Model 2: Parasitas ~ Femeas + Idade\n#>   #Df  LogLik Df Chisq Pr(>Chisq)\n#> 1   7 -56.228                    \n#> 2   5 -56.657 -2 0.859     0.6508\n\nanova(modelo_ancova2)\n#> Analysis of Variance Table\n#> \n#> Response: Parasitas\n#>           Df Sum Sq Mean Sq F value  Pr(>F)  \n#> Femeas     2 111.58  55.789  3.4980 0.05341 .\n#> Idade      1 113.53 113.527  7.1183 0.01622 *\n#> Residuals 17 271.13  15.949                  \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Criando modelo sem tamanho do corpo\nmodelo_ancova3 <- lm(Parasitas ~ Idade, data = exercicio_8)\n\n## Likelihood-ratio test\nlrtest(modelo_ancova2, modelo_ancova3)\n#> Likelihood ratio test\n#> \n#> Model 1: Parasitas ~ Femeas + Idade\n#> Model 2: Parasitas ~ Idade\n#>   #Df  LogLik Df  Chisq Pr(>Chisq)\n#> 1   5 -56.657                     \n#> 2   3 -57.087 -2 0.8584      0.651\n\nanova(modelo_ancova3)\n#> Analysis of Variance Table\n#> \n#> Response: Parasitas\n#>           Df Sum Sq Mean Sq F value   Pr(>F)   \n#> Idade      1 213.79 213.792  14.382 0.001231 **\n#> Residuals 19 282.44  14.865                    \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Gráfico\nggplot(data = exercicio_8, aes(x = Idade, y = Parasitas)) + \n  labs(x = \"Idade das aves\", y = \"Número de parasitas\") +\n  geom_point(size = 6, shape = 19, alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)\n# Carregar a planilha com os dados\nexercicio_9 <- ecodados::Cap7_exercicio9\n\n## Análise anova em blocos\nmodel_bloco <- aov(Riqueza ~ Predadores + Error(Lago), data = exercicio_9)\n\nsummary(model_bloco)\n#> \n#> Error: Lago\n#>           Df Sum Sq Mean Sq F value Pr(>F)\n#> Residuals  1 0.2561  0.2561               \n#> \n#> Error: Within\n#>            Df Sum Sq Mean Sq F value Pr(>F)  \n#> Predadores  1  120.0  120.05   4.743 0.0438 *\n#> Residuals  17  430.2   25.31                 \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Gráfico\nggplot(data = exercicio_9, aes(x = Predadores, y = Riqueza)) + \n  geom_boxplot(color = \"black\", show.legend = FALSE, alpha = 0.4) +\n  geom_jitter(size = 4, width = 0.1) +\n  labs(x = \"Predadores\", y = \"Riqueza de macroinvertebrados\") +\n  theme_bw(base_size = 16)\n# Carregar a planilha com os dados\nexercicio_10 <- ecodados::anuros_ambientais\n\n## Modelo gls sem estrutura espacial\nno_spat_gls <- gls(Riqueza ~ Prec_anual, exercicio_10, method = \"REML\")\n\n## Covariância esférica\nespher_model <- gls(Riqueza ~ Prec_anual, exercicio_10, \n                    corSpher(form = ~Latitude + Longitude, nugget = TRUE))\n\n## Covariância exponencial\nexpon_model <- gls(Riqueza ~ Prec_anual, exercicio_10, \n                   corExp(form = ~Latitude + Longitude, nugget = TRUE))\n\n## Covariância Gaussiana\ngauss_model <- gls(Riqueza ~ Prec_anual, exercicio_10, \n                   corGaus(form = ~Latitude + Longitude, nugget = TRUE))\n\n## Covariância linear\ncor_linear_model <- gls(Riqueza ~ Prec_anual, exercicio_10, \n                        corLin(form = ~Latitude + Longitude, nugget = TRUE))\n\n## Covariância razão quadrática\nratio_model <- gls(Riqueza ~ Prec_anual, exercicio_10, \n                   corRatio(form = ~Latitude + Longitude, nugget = TRUE))\n\n## Seleção de modelos\naic_fit <- AIC(no_spat_gls, espher_model, expon_model, \n               cor_linear_model, gauss_model,ratio_model)\naic_fit %>% arrange(AIC)\n#>                  df      AIC\n#> cor_linear_model  5 344.1434\n#> gauss_model       5 344.3118\n#> ratio_model       5 344.8400\n#> no_spat_gls       3 345.4316\n#> espher_model      5 345.6006\n#> expon_model       5 346.2936\n\n\n## Gráfico\nplot(residuals(cor_linear_model, type = \"normalized\") ~ fitted(cor_linear_model))\n\n## Varigrama\ncor_linear_variog <- Variogram(cor_linear_model, form = ~Latitude + Longitude,\n                               resType = \"normalized\")\n\nplot(cor_linear_variog, main = \"Variograma como Modelo de Covariância Linear\")\n\n## Resumo dos modelos\nsummary(cor_linear_model)$tTable \n#>                   Value    Std.Error  t-value   p-value\n#> (Intercept) 17.25918513 73.686338088 0.234225 0.8159483\n#> Prec_anual   0.01316726  0.008113421 1.622899 0.1120944\nsummary(no_spat_gls)$tTable\n#>                   Value  Std.Error    t-value      p-value\n#> (Intercept) -3.35797556 8.99912469 -0.3731447 0.7109175029\n#> Prec_anual   0.02288015 0.00630715  3.6276526 0.0007686691"},{"path":"cap.-10---rarefação.html","id":"cap.-10---rarefação","chapter":"Cap. 10 - Rarefação","heading":"Cap. 10 - Rarefação","text":"10.1\nAvalie se diferentes tipos de uso da terra (fragmento florestal, borda de mata, área de pastagem e cana de açúcar) apresentam diferentes riquezas de espécies? Qual sua interpretação? Faça um gráfico com os resultados.Solução:¨10.2O estudo é o mesmo exercício anterior. Contudo, ao invés da rarefação baseada na abundância, faça rarefações baseadas número de amostras. Qual sua interpretação considerando os resultados exercício 1? Faça um gráfico com os resultados.Solução:¨10.3\nUse os dados dos exercícios anteriores e calcule rarefação baseada na cobertura de amostragem (coverage-based). Qual sua interpretação considerando os resultados anteriores? Faça um gráfico com os resultados.Solução:¨","code":"\n# Pacotes necessários\nlibrary(iNEXT)\nlibrary(ecodados)\nlibrary(ggplot2)\n# Carregar a planilha com os dados\nexercicio_1 <- ecodados::Cap10_exercicio1\n\n## Número de indivíduos por local\ncolSums(exercicio_1)\n#> Fragmento     Pasto     Borda      Cana \n#>        91        60       106       152\n\n## Análise de rarefação\nresultados_exercicio_1 <- iNEXT(exercicio_1, q = 0, \n                             datatype = \"abundance\", endpoint = 300)\n\n## Gráfico\nggiNEXT(resultados_exercicio_1, type = 1) +\n  geom_vline(xintercept = 60, lty = 2) +\n  scale_linetype_discrete(labels = c(\"Interpolado\", \"Extrapolado\")) +\n  scale_colour_manual(values = c(\"darkorange\", \"darkorchid\", \"cyan4\", \"black\")) +\n  scale_fill_manual(values = c(\"darkorange\", \"darkorchid\", \"cyan4\", \"black\")) +\n  labs(x = \"Número de indivíduos\", y = \" Riqueza de espécies\") +\n  theme_bw(base_size = 16)\n# Carregar a planilha com os dados\nexercicio_2 <- ecodados::Cap10_exercicio2\n\n# Verificar se carregou corretamente \nhead(exercicio_2)\n#>          Fragmento Pasto Borda Cana\n#> amostras        10    14    10    9\n#> sp1              5     0     2    0\n#> sp2              1     5     1    0\n#> sp3              4     0     3    0\n#> sp4              1    14     5    1\n#> sp5              6     0     3    1\n\n\n## Análise de rarefação\nresultados_exercicio_2 <- iNEXT(exercicio_2, q = 0, \n                                datatype = \"incidence_freq\", endpoint = 30)\n\n## Gráfico\nggiNEXT(resultados_exercicio_2, type = 1, color.var = \"site\") +\n  geom_vline(xintercept = 9, lty = 2) +\n  scale_linetype_discrete(labels = c(\"Interpolado\", \"Extrapolado\")) +\n  scale_colour_manual(values = c(\"darkorange\", \"darkorchid\", \"cyan4\", \"black\")) +\n  scale_fill_manual(values = c(\"darkorange\", \"darkorchid\", \"cyan4\", \"black\")) +\n  labs(x = \"Número de amostras\", y = \" Riqueza de espécies\") +\n  theme_bw(base_size = 16)\n# Rarefação considerando a cobertura da abundância \nresultados_exercicio_1 <- iNEXT(exercicio_1, q = 0, \n                             datatype = \"abundance\", endpoint = 300)\n\n## Gráfico\n# Visualizar os resultados da rarefação *coverage-based*. \nggiNEXT(resultados_exercicio_1, type = 3, color.var = \"site\") + \n    scale_linetype_discrete(labels = c(\"Interpolado\", \"Extrapolado\")) +\n    scale_colour_manual(values = c(\"darkorange\", \"darkorchid\", \"cyan4\", \"black\")) +\n    scale_fill_manual(values = c(\"darkorange\", \"darkorchid\", \"cyan4\", \"black\")) +\n    labs(x = \"Representatividade da abundância\", y = \"Riqueza de espécies\") +\n    theme_bw(base_size = 16)\n\n\n# Rarefação considerando a cobertura das amostras \nresultados_exercicio_2 <- iNEXT(exercicio_2, q = 0, \n                                datatype = \"incidence_freq\", endpoint = 30)\n\n## Gráfico\n# Visualizar os resultados da rarefação *coverage-based*. \nggiNEXT(resultados_exercicio_2, type = 3, color.var = \"site\") + \n    scale_linetype_discrete(labels = c(\"Interpolado\", \"Extrapolado\")) +\n    scale_colour_manual(values = c(\"darkorange\", \"darkorchid\", \"cyan4\", \"black\")) +\n    scale_fill_manual(values = c(\"darkorange\", \"darkorchid\", \"cyan4\", \"black\")) +\n    labs(x = \"Representatividade das amostras\", y = \"Riqueza de espécies\") +\n    theme_bw(base_size = 16)"},{"path":"cap.-11---estimadores-de-riqueza.html","id":"cap.-11---estimadores-de-riqueza","chapter":"Cap. 11 - Estimadores de riqueza","heading":"Cap. 11 - Estimadores de riqueza","text":"11.1\nCarregue os dados - Cap11_exercicio1 - que está pacote ecodados. Este conjunto de dados representa abundância de 50 espécies de besouros coletados em 30 amostras. Calcule os estimadores de riqueza - Chao1 e ACE - e faça um gráfico contendo riqueza observada e os dois estimadores de riqueza. Qual sua interpretação sobre o esforço amostral?Solução:11.2Utilize o mesmo conjunto de dados exercício anterior. Calcule os estimadores de riqueza - Jackknife 1 e bootstrap. Faça um gráfico contendo riqueza observada e os dois estimadores de riqueza. Qual sua interpretação sobre o esforço amostral? Compare com os resultados exercício anterior que utilizam estimadores baseados na abundância das espécies.Solução:11.3\nVamos refazer o exercício 10 Capítulo 7 que usa Generalized Least Squares (GLS) para testar relação da riqueza de anuros em 44 localidades na Mata Atlântica com precipitação anual. Contudo, ao invés de considerar riqueza de espécies de anuros observada como variável resposta, iremos utilizar riqueza extrapolada. Utilize os dados “anuros_composicao” para estimar riqueza extrapolada e o dados “anuros_ambientais” para acessar os dados de precipitação anual e coordenadas geográficas. Qual sua interpretação dos resultados utilizando riqueza observada e extrapolada?Solução:","code":"\n# Pacotes necessários\nlibrary(iNEXT)\nlibrary(ecodados)\nlibrary(ggplot2)\nlibrary(vegan)\nlibrary(nlme)\nlibrary(dplyr)\n# Carregar a planilha com os dados\nexercicio_1 <- ecodados::Cap11_exercicio1\n\n# estimadores abundância\nest_abun <- estaccumR(exercicio_1, permutations = 100)\n\n## Preparando os dados para fazer o gráfico\nresultados_abun <- summary(est_abun \n                          , display = c(\"S\", \"chao\", \"ace\"))\nres_abun <- cbind(resultados_abun$chao[, 1:4], resultados_abun$ace[, 2:4], \n                 resultados_abun$S[, 2:4])\nres_abun <- as.data.frame(res_abun)\ncolnames(res_abun) <- c(\"Amostras\", \"Chao\", \"C_inferior\", \"C_superior\", \n                       \"ace\", \"A_inferior\", \"A_superior\",\n                        \"Riqueza\", \"R_inferior\", \"R_superior\")\n\n\n## Gráfico\nggplot(res_abun, aes(y = Riqueza, x = Amostras)) +\n    geom_point(aes(y = Chao, x = Amostras + 0.1), size = 4, \n               color = \"darkorange\", alpha = 1) +\n    geom_point(aes(y = ace, x = Amostras + 0.2), size = 4, \n               color = \"cyan4\", alpha = 1) +\n    geom_point(aes(y = Riqueza, x = Amostras), size = 4, \n               color = \"black\", alpha = 1) +\n    geom_point(y = 150, x = 1, size = 4, color = \"darkorange\", alpha = 1) + \n    geom_point(y = 135, x = 1, size = 4, color = \"cyan4\", alpha = 1) + \n    geom_point(y = 120, x = 1, size = 4, color = \"black\", alpha = 1) +\n    geom_label(y = 150, x = 4.4, label = \"Chao 1\", size = 5) +\n    geom_label(y = 135, x = 3.9, label = \"ACE\", size = 5) +\n    geom_label(y = 120, x = 7.3, label = \"Riqueza observada\", size = 5) + \n    geom_line(aes(y = Chao, x = Amostras), color = \"darkorange\") +\n    geom_line(aes(y = ace, x = Amostras), color = \"cyan4\") +\n    geom_line(aes(y = Riqueza, x = Amostras), color = \"black\") +\n    geom_linerange(aes(ymin = C_inferior, ymax = C_superior,\n                       x = Amostras + 0.1), color = \"darkorange\") +\n    geom_linerange(aes(ymin = A_inferior, ymax = A_superior,\n                       x = Amostras + 0.2), color = \"cyan4\") +\n    geom_linerange(aes(ymin = R_inferior, ymax = R_superior,\n                       x = Amostras), color = \"black\") +\n    scale_x_continuous(limits = c(1, 31), breaks = seq(1, 31, 1)) +\n    labs (x = \"Número de amostras\", y = \"Riqueza de espécies de besouros\") +\n    theme_bw(base_size = 12) +\n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n# Carregar a planilha com os dados\nexercicio_1 <- ecodados::Cap11_exercicio1\n\n# estimadores incidencia\nest_inc <- poolaccum(exercicio_1, permutations = 100)\n\n## Preparando os dados para fazer o gráfico\nresultados_inc <- summary(est_inc \n                          , display = c(\"S\", \"jack1\", \"boot\"))\nres_inc <- cbind(resultados_inc$jack1[, 1:4], resultados_inc$boot[, 2:4], \n                 resultados_inc$S[, 2:4])\nres_inc <- as.data.frame(res_inc)\ncolnames(res_inc) <- c(\"Amostras\", \"jack1\", \"j_inferior\", \"j_superior\", \n                       \"boot\", \"B_inferior\", \"B_superior\",\n                        \"Riqueza\", \"R_inferior\", \"R_superior\")\n\n\n## Gráfico\nggplot(res_inc, aes(y = Riqueza, x = Amostras)) +\n    geom_point(aes(y = jack1, x = Amostras + 0.1), size = 4, \n               color = \"darkorange\", alpha = 1) +\n    geom_point(aes(y = boot, x = Amostras + 0.2), size = 4, \n               color = \"cyan4\", alpha = 1) +\n    geom_point(aes(y = Riqueza, x = Amostras), size = 4, \n               color = \"black\", alpha = 1) +\n    geom_point(y = 70, x = 1, size = 4, color = \"darkorange\", alpha = 1) + \n    geom_point(y = 65, x = 1, size = 4, color = \"cyan4\", alpha = 1) + \n    geom_point(y = 60, x = 1, size = 4, color = \"black\", alpha = 1) +\n    geom_label(y = 70, x = 4.9, label = \"Jackknife 1\", size = 5) +\n    geom_label(y = 65, x = 4.6, label = \"Bootstrap\", size = 5) +\n    geom_label(y = 60, x = 6.7, label = \"Riqueza observada\", size = 5) + \n    geom_line(aes(y = jack1, x = Amostras), color = \"darkorange\") +\n    geom_line(aes(y = boot, x = Amostras), color = \"cyan4\") +\n    geom_line(aes(y = Riqueza, x = Amostras), color = \"black\") +\n    geom_linerange(aes(ymin = j_inferior, ymax = j_superior,\n                       x = Amostras + 0.1), color = \"darkorange\") +\n    geom_linerange(aes(ymin = B_inferior, ymax = B_superior,\n                       x = Amostras + 0.2), color = \"cyan4\") +\n    geom_linerange(aes(ymin = R_inferior, ymax = R_superior,\n                       x = Amostras), color = \"black\") +\n    scale_x_continuous(limits = c(1, 31), breaks = seq(1, 31, 1)) +\n    labs (x = \"Número de amostras\", y = \"Riqueza de espécies de besouros\") +\n    theme_bw(base_size = 12) +\n    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n# Carregar a planilha com os dados\nexercicio_3 <- ecodados::anuros_composicao\n\n# Verificar a comunidade com maior abundãncia. \nabund_max <- max(colSums(exercicio_3))\n\n# Calcular a riqueza extrapolada de espécies para todas as comunidades \n# considerando a maior abundância. \nresultados_extrapolacao <- iNEXT(exercicio_3, q = 0, \n                                 datatype = \"abundance\", \n                                 endpoint = abund_max)\n\n# Loop para determinar a riqueza extrapolada para as 44 localidades\nresultados_comunidades_ext <- data.frame()\nriqueza_extrapolada <- c()\n\nfor (i in 1:44){\n    resultados_comunidades_ext <- data.frame(resultados_extrapolacao$iNextEst[i])\n    riqueza_extrapolada[i] <- resultados_comunidades_ext[40, 4] \n}\n\n\n# carregando o data frame com todas as variáveis\nexercicio_3_1 <- ecodados::anuros_ambientais\n\n# Criando um data frame com a riqueza extrapolada, precipitação anual,\n# latitude e longitude\ndados_combinado_ext <- data.frame(riqueza_extrapolada, exercicio_3_1[,c(3,5,6)])\n\n\n## Modelo gls sem estrutura espacial\nno_spat_gls <- gls(riqueza_extrapolada ~ Prec_anual, dados_combinado_ext, method = \"REML\")\n\n## Covariância esférica\nespher_model <- gls(riqueza_extrapolada ~ Prec_anual, dados_combinado_ext, \n                    corSpher(form = ~Latitude + Longitude, nugget = TRUE))\n\n## Covariância exponencial\nexpon_model <- gls(riqueza_extrapolada ~ Prec_anual, dados_combinado_ext, \n                   corExp(form = ~Latitude + Longitude, nugget = TRUE))\n\n## Covariância Gaussiana\ngauss_model <- gls(riqueza_extrapolada ~ Prec_anual, dados_combinado_ext, \n                   corGaus(form = ~Latitude + Longitude, nugget = TRUE))\n\n## Covariância linear\ncor_linear_model <- gls(riqueza_extrapolada ~ Prec_anual, dados_combinado_ext, \n                        corLin(form = ~Latitude + Longitude, nugget = TRUE),\n                        control = glsControl(opt='optim',  msVerbose = F))\n\n## Covariância razão quadrática\nratio_model <- gls(riqueza_extrapolada ~ Prec_anual, dados_combinado_ext, \n                   corRatio(form = ~Latitude + Longitude, nugget = TRUE))\n\n## Seleção de modelos\naic_fit <- AIC(no_spat_gls, espher_model, cor_linear_model, expon_model, \n               gauss_model,ratio_model)\naic_fit %>% arrange(AIC)\n#>                  df      AIC\n#> no_spat_gls       3 338.8380\n#> gauss_model       5 339.6672\n#> ratio_model       5 339.6853\n#> expon_model       5 340.3431\n#> espher_model      5 342.8380\n#> cor_linear_model  5 342.8489\n\n\n## Gráfico\nplot(residuals(espher_model, type = \"normalized\") ~ fitted(espher_model))\n\n## Varigrama\nespher_model_variog <- Variogram(espher_model, form = ~Latitude + Longitude,\n                               resType = \"normalized\")\n\nplot(espher_model_variog, main = \"Variograma com o modelo de Covariância Esférica\")\n\n## Resumo dos modelos\nsummary(espher_model)$tTable \n#>                 Value   Std.Error   t-value     p-value\n#> (Intercept) 3.7004741 8.319750795 0.4447818 0.658761200\n#> Prec_anual  0.0173344 0.005831002 2.9727995 0.004869827\nsummary(no_spat_gls)$tTable\n#>                 Value   Std.Error   t-value     p-value\n#> (Intercept) 3.7004741 8.319750757 0.4447818 0.658761200\n#> Prec_anual  0.0173344 0.005831002 2.9727995 0.004869827"},{"path":"cap.-12---diversidade-taxônomica.html","id":"cap.-12---diversidade-taxônomica","chapter":"Cap. 12 - Diversidade Taxônomica","heading":"Cap. 12 - Diversidade Taxônomica","text":"12.1\nCarregue os dados - anuros_composicao - que está pacote ecodados. Este conjunto de dados representa abundância de 211 espécies de anuros coletados em 44 localidades na Mata Atlântica. Calcule riqueza de espécies para cada comunidade e os índices de Margalef, Menhinich, Shannon-Wiener, Gini-Simpson e Equitabilidade de Pielou. Salve todos os resultados em novo data frame. Faça uma gráfico usando o função ggpairs para ver correlação entre métricas. Qual sua interpretação sobre os resultados?Solução:11.2\nUsando os resultados anteriores, selecione duas comunidades com os maiores e menores valores de Shannon-Wiener. Em seguida, faça um Diagrama de Whittaker. Por fim, interprete curvas considerando curvas teóricas (.e., geométrica, broken-stick, etc.) descritas nos livros de ecologia.Solução:11.3\nUsando os dados - anuros_composicao - calcule partição da diversidade beta considerando os dados de abundância e presença e ausência. ) Faça um gráfico boxplot com os resultados. Discuta se os resultados usando abundância ou presença e ausência são congruentes ou discrepantes. b) Calcule distância geográfica (use planilha anuros_ambientais) entre localidaes (use Distância euclidiana). Em seguida, faça uma análise de regressão para verificar se localidades que estão próximas apresentam maior similaridade na composição de espécies (use componente turnover - Bsim) que comunidades que estão distantes (e.g., Decaimento da similaridade).Solução:","code":"\n# Pacotes necessários\nlibrary(devtools)\nlibrary(ecodados)\nlibrary (vegan)\nlibrary(ggplot2)\nlibrary(BiodiversityR)\nlibrary(hillR)\nlibrary(betapart)\nlibrary(GGally)\n# Carregar a planilha com os dados\nexercicio_1 <- ecodados::anuros_composicao\n\n# Transpor o data frame para as espécies ficarem nas colunas e as localidades nas linhas\nexercicio_1_t <- data.frame(t(exercicio_1))\n\n## Calculando a riqueza observada de espécies para cada comunidade\nRiqueza <- specnumber(exercicio_1_t)\n\n## Calculando o Índice de Margalef para cada comunidade\nMargalef <- round((Riqueza - 1)/log(apply(exercicio_1_t, 1, sum)), 2)\n\n## Calculando o Índice de Menhinick para cada comunidade\nMenhinick <- round(Riqueza/sqrt(apply(exercicio_1_t, 1, sum)), 2)\n\n## Calculando o Índice de Shannon-Wiener para cada comunidade\nShannon <- round(diversity(exercicio_1_t, index = \"shannon\", MARGIN = 1), 2)\n\n## Calculando o Índice de Gini-Simpson para cada comunidade\nGini_Simpson <- round(diversity(exercicio_1_t, index = \"simpson\", MARGIN = 1), 2)\n\n## Calculando o Índice de Equitabilidade de Pielou para cada comunidade\nPielou <- round(Shannon/log(Riqueza), 2)\n\n# Criando data frame\nresultados <- data.frame(Riqueza, Margalef, Menhinick, Shannon, Gini_Simpson, Pielou)\n\n# Gráfico\nggpairs(resultados, upper = list(continuous = wrap(\"cor\", size = 4))) +\n    tema_livro()\n# Usando os resultados no exercício anterior, vamos verificar quais são as comunidades com maiores e menores valores de Shannon-Wienner\norder(resultados$Shannon)\n#>  [1] 43 37 12  4 41  1 16 38 19 11 22 44 20 13 10 29 17 24\n#> [19] 42  8 15 25 31  7  5 14 18  3 21 39 40 32 30 34 33 27\n#> [37] 36  9  2 35 26  6 28 23\n\n# AS comunidades com maiores valores estão nas linhas 6 e 23 e as comunidades com menores valores nas linhas 43 e 37.\nrank_com6 <- rankabundance(exercicio_1_t[6, exercicio_1_t[6,] > 0])\nrank_com23 <- rankabundance(exercicio_1_t[23, exercicio_1_t[23,] > 0])\nrank_com43 <- rankabundance(exercicio_1_t[43, exercicio_1_t[43,] > 0])\nrank_com37 <- rankabundance(exercicio_1_t[37, exercicio_1_t[37,] > 0])\n\n## Gráfico\nrankabunplot(rank_com6, scale = \"logabun\", pch = 19, specnames = NULL, \n             col = \"darkorange\")\nrankabunplot(rank_com23, scale = \"logabun\", pch = 19, specnames = NULL,\n             addit = TRUE, col = \"red\")\nrankabunplot(rank_com43, scale = \"logabun\", pch = 19, specnames = NULL,\n             addit = TRUE, col = \"cyan4\" )\nrankabunplot(rank_com37, scale = \"logabun\", pch = 19, specnames = NULL,\n            addit = TRUE, col = \"darkblue\" )\nlegend(20, 8, legend = c(\"Comunidade 6\", \"Comunidade 23\", \n                         \"Comunidade 43\", \"Comunidade 37\"),\n       col = c(\"darkorange\", \"red\", \"cyan4\", \"darkblue\"), lty = 1, lwd = 3, \n       cex = 1.2, box.lty = 0)\n# Carregar a planilha com os dados\nanuros <- ecodados::anuros_composicao\n\n# Transpor o data frame \nanuros_t <- data.frame(t(anuros))\n\n## Transformando dados em presencia e ausência.\nanuros_PA <- decostand(anuros_t, method = \"pa\")\n\n## Diversidade beta presença e ausência\nresultado_PA <- beta.pair(anuros_PA, index.family = \"sorensen\")\n\n## Diversidade beta abundância\nresultado_Abund <- beta.pair.abund(anuros_t, index.family = \"bray\")\n\n## Criando data frame com os resultados\ndiver_beta <- c(round(as.numeric(resultado_PA$beta.sor), 2),\n                            round(as.numeric(resultado_PA$beta.sim), 2),\n                            round(as.numeric(resultado_PA$beta.sne), 2),\n                            round(as.numeric(resultado_Abund$beta.bray), 2),\n                            round(as.numeric(resultado_Abund$beta.bray.bal), 2),\n                            round(as.numeric(resultado_Abund$beta.bray.gra), 2))\n\nComponentes <- rep(c(\"Bsor\", \"Bsim\", \"Bnes\", \"BBray\", \"BBray_bal\", \"BBray_gra\"),\n             each = 946)\nDados <- rep(c(\"Incidencia\", \"Abundância\"),\n             each = 2838)\n\ndata_frame <- data.frame(diver_beta, Componentes, Dados)\n\n# Reordenando os componentes para melhorar visualização no gráfico\ndata_frame$Componentes <- factor(data_frame$Componentes , levels=c(\"Bsor\", \"Bsim\", \"Bnes\", \n                                           \"BBray\", \"BBray_bal\", \"BBray_gra\"))\n\n## Gráfico\nggplot(data_frame, aes(y = diver_beta , x = Componentes, fill = Dados)) + \n  geom_boxplot() +\n  theme_bw(base_size = 16) +\n  geom_jitter(size = 0.3, width = 0.05) +\n  labs( x = \"Componentes diversidade beta\", y = \"Dissimilaridade\")\n\n\n## carregando planilha anuros_ambientais\n\nambientes <- ecodados::anuros_ambientais\n\n## Distância euclidiana\ndistancia <- vegdist(ambientes[,c(6,7)], \"euclidean\")\n\n## criar data frame\n\ndados <- data.frame(round(as.numeric(resultado_PA$beta.sim), 2), \n                    round(as.numeric(distancia), 2))\n\ncolnames(dados) <- c(\"Bsim\", \"distancia\")\n\n## Regressão - Contudo essa não é a melhor análise porque os índices de \n# diversidade beta apresenta um platô.\nregr <- lm (dados$Bsim ~ dados$distancia)\nsummary(regr)\n#> \n#> Call:\n#> lm(formula = dados$Bsim ~ dados$distancia)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -0.58919 -0.21205  0.03911  0.19848  0.50133 \n#> \n#> Coefficients:\n#>                  Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)     0.4729768  0.0129279   36.59   <2e-16 ***\n#> dados$distancia 0.0075119  0.0007092   10.59   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.2472 on 944 degrees of freedom\n#> Multiple R-squared:  0.1062, Adjusted R-squared:  0.1053 \n#> F-statistic: 112.2 on 1 and 944 DF,  p-value: < 2.2e-16\n\n## Gráfico\nggplot(data = dados, aes(x = distancia*10, y = Bsim)) + \n  labs(x = \"Distância geográfica (km)\", y = \"Componente substituição diversidade beta\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)"},{"path":"cap.-13---diversidade-filogenética.html","id":"cap.-13---diversidade-filogenética","chapter":"Cap. 13 - Diversidade Filogenética","heading":"Cap. 13 - Diversidade Filogenética","text":"13.1\nCarregue os dados - anuros_composicao (.e., 211 espécies de anuros coletados em 44 localidades na Mata Atlântica), anuros_ambientais (.e., variáveis climáticas, topográficas e coordenadas geográficas) & filogenia_anuros (filogenia das 211 espécies) - que estão pacote ecodados. Use função varpartdo pacote vegan para testar importância relativa dos efeitos da precipitação anual, range altitudinal e temperatura anual na distribuição espacial da diversidade filogenética (PD) e Endemismo filogenético (PE). Calcule o SES para verificar se os resultados da diversidade filogenética (PD) diferem esperado ao acaso devido ao número de espécies em cada comunidade. Qual sua interpretação sobre os resultados?Solução:13.2\nCarregue os dados - anuros_composicao (.e., 211 espécies de anuros coletados em 44 localidades na Mata Atlântica), anuros_ambientais (.e., variáveis climáticas, topográficas e coordenadas geográficas) & filogenia_anuros (filogenia das 211 espécies) - que estão pacote ecodados. Use função varpartdo pacote vegan para testar importância relativa dos efeitos da precipitação anual, range altitudinal e temperatura anual na distribuição espacial NRI e NTI. Qual sua interpretação sobre os resultados?Solução:13.3\nCarregue os dados - anuros_composicao (.e., 211 espécies de anuros coletados em 44 localidades na Mata Atlântica), anuros_ambientais (.e., variáveis climáticas, topográficas e coordenadas geográficas) & filogenia_anuros (filogenia das 211 espécies) - que estão pacote ecodados. Use função varpartdo pacote vegan para testar importância relativa dos efeitos da precipitação anual, range altitudinal e distância geográfica na distribuição espacial dos diferentes componentes da diversidade beta filogenética (Phylosor). Qual sua interpretação sobre os resultados?Solução:","code":"\n# Pacotes necessários\nlibrary(devtools)\nlibrary(ecodados)\nlibrary(V.PhyloMaker)\nlibrary(vegan)\nlibrary(ggplot2)\nlibrary(GGally)\nlibrary(ggpubr)\nlibrary(picante)\nlibrary(phytools)\nlibrary(ape)\nlibrary(geiger)\nlibrary(phyloregion)\nlibrary(pez)\nlibrary(reshape2)\nlibrary(betapart)\nlibrary(bbmle)\nlibrary(vegan)\n# Carregar as planilhas com os dados\nanuros <- ecodados::anuros_composicao\nanuros_t <- t(anuros) # Transpor dados\nambiente <- ecodados::anuros_ambientais\nfilogenia <- ecodados::filogenia_anuros\n\n## Conferir os nomes das espécies\nname.check(filogenia, anuros)\n#> [1] \"OK\"\n\n\n## Colocar os nomes das espécies do data frame na mesma ordem que aparecem na filogenia\nanuros_P <- match.phylo.comm(phy = filogenia, comm = anuros_t)$comm\n\n## Phylogenetic diversity (PD)\n#*****************************************************************************\nanuros_PD <- pd(anuros_P, filogenia)\n\n## Criar data frame\ndados <- data.frame(anuros_PD$PD, anuros_PD$SR, ambiente$Prec_anual,\n                    ambiente$Range_altitude, ambiente$Temp_anual)\ncolnames(dados) <- c(\"PD\", \"SR\", \"Prec_anual\", \"Range_altitude\", \"Temp_anual\")\n\n## Partição da variância\nparticao_PD <- varpart(dados$PD, dados$Prec_anual, \n                    dados$Range_altitude, dados$Temp_anual)\nplot (particao_PD, digits = 1, Xnames = c('Precipitação', 'Altitude', 'Temperatura'), \n      bg = c('navy', 'darkorange', 'green'))\n\n## Gráfico\nggplot(data = dados, aes(x = Prec_anual, y = PD)) + \n  labs(x = \"Precipitação anual (mm)\", y = \"Diversidade filogenética (PD)\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)\n\n\n## Phylogenetic Endemism (PE)\n#***************************************************************************\n# Transformando data.frame em matriz.\nanuros_matriz <- as.matrix(anuros_P)\nanuros_PE <- phylo_endemism(anuros_matriz, filogenia, weighted = TRUE)\n\n## Adicionando no data frame\ndados$PE <- anuros_PE\n\n## Partição da variância\nparticao_PE <- varpart(dados$PE, dados$Prec_anual, \n                    dados$Range_altitude, dados$Temp_anual)\nplot (particao_PE, digits = 1, Xnames = c('Precipitação', 'Altitude', 'Temperatura'), \n      bg = c('navy', 'darkorange', 'green'))\n\n## Gráfico\nggplot(data = dados, aes(x = Prec_anual, y = PE)) + \n  labs(x = \"Precipitação anual (mm)\", y = \"Endemismo filogenético (PE)\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)\n\n\n## Standardized Effect Size (SES) para o PD\n#*****************************************************************************\nresultados_SES_PD <- ses.pd(anuros_P, filogenia,\n                            null.model = \"independentswap\", \n                            runs = 999) \n\n## Adicionando no data frame\ndados$SES <- resultados_SES_PD$pd.obs.z\n\n## Partição da variância\nparticao_SES <- varpart(dados$SES, dados$Prec_anual, \n                    dados$Range_altitude, dados$Temp_anual)\nplot (particao_SES, digits = 1, Xnames = c('Precipitação', 'Altitude', 'Temperatura'), \n      bg = c('navy', 'darkorange', 'green'))\n\n## Gráfico\nggplot(data = dados, aes(x = Prec_anual, y = SES)) + \n  labs(x = \"Precipitação anual (mm)\", y = \"Standardized Effect Size  (PD)\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)\n\n## Nearest Relative Index (NRI)\n#*****************************************************************************\nresultados_NRI <- ses.mpd(anuros_P, cophenetic(filogenia),\n                              null.model = \"taxa.labels\", \n                              abundance.weighted = FALSE,\n                              runs = 999)\n\n## Inserir no data frame\ndados$NRI <- -1*(resultados_NRI$mpd.obs.z)\n\n## Partição da variância\nparticao_NRI <- varpart(dados$NRI, dados$Prec_anual, \n                    dados$Range_altitude, dados$Temp_anual)\nplot (particao_NRI, digits = 1, Xnames = c('Precipitação', 'Altitude', 'Temperatura'), \n      bg = c('navy', 'darkorange', 'green'))\n\n## Gráfico\nggplot(data = dados, aes(x = Range_altitude, y = NRI)) + \n  labs(x = \"Range altitudinal (m)\", y = \"Nearest Relative Index (NRI)\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)\n\n## Nearest Taxon Index (NTI)\n#*****************************************************************************\nresultados_NTI <- ses.mntd(anuros_P, cophenetic(filogenia),\n                              null.model = \"taxa.labels\", \n                              abundance.weighted = FALSE,\n                              runs = 999)\n\n## Inserir no data frame\ndados$NTI <- -1*(resultados_NTI$mntd.obs.z)\n\n## Partição da variância\nparticao_NTI <- varpart(dados$NTI, dados$Prec_anual, \n                    dados$Range_altitude, dados$Temp_anual)\nplot (particao_NTI, digits = 1, Xnames = c('Precipitação', 'Altitude', 'Temperatura'), \n      bg = c('navy', 'darkorange', 'green'))\n\n## Gráfico\nggplot(data = dados, aes(x = Range_altitude, y = NTI)) + \n  labs(x = \"Precipitação anual (mm)\", y = \"Nearest Taxon Index (NTI)\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)\n\n# Temos que transformar os dados para presença e ausência das espécies nas comunidades.\nanuros_PA <- decostand(anuros_P, \"pa\")\n\n## Phylosor\n#*****************************************************************************\n# Partição dos componentes do Phylosor.\nresultados_Phylosor <- phylo.beta.pair(anuros_PA,\n                                                filogenia, \n                                                index.family = \"sorensen\")\n\n## vamos calcular a similaridade entre as variáveis ambientais\nprec_dist <- vegdist(ambiente$Prec_anual, \"euclidian\")\nalt_dist <- vegdist(ambiente$Range_altitude, \"euclidian\")\ncoord_dist <- vegdist(ambiente[,c(5,6)], \"euclidian\")\n\n# Vamos preparar os dados .\ndados_phylosor <- data.frame(\n    substituicao = as.numeric(resultados_Phylosor$phylo.beta.sim),\n    aninhamento = as.numeric(resultados_Phylosor$phylo.beta.sne),\n    sorensen = as.numeric(resultados_Phylosor$phylo.beta.sor),\n    dis_prec = as.numeric(prec_dist),\n    dis_alt = as.numeric(alt_dist),\n    dis_coord = as.numeric(coord_dist))\n\n## Partição da variância do componente substituição do Phylosor\n#*******************************************************************************\nparticao_subst <- varpart(dados_phylosor$substituicao, dados_phylosor$dis_prec, \n                    dados_phylosor$dis_alt, dados_phylosor$dis_coord)\nplot (particao_subst, digits = 1, Xnames = c('Precipitação', 'Altitude', 'Distância'), \n      bg = c('navy', 'darkorange', 'green'))\n\n## Gráfico\nggplot(data = dados_phylosor, aes(x = dis_coord*10, y = substituicao)) + \n  labs(x = \"Distância geográfical (km)\", \n       y = \"Componente substituição da diversidade beta \\n filogenética (Phylosor)\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)\n\n## Partição da variância do componente aninhamento do Physolor\n#*******************************************************************************\nparticao_anin <- varpart(dados_phylosor$aninhamento, dados_phylosor$dis_prec, \n                    dados_phylosor$dis_alt, dados_phylosor$dis_coord)\nplot (particao_anin, digits = 1, Xnames = c('Precipitação', 'Altitude', 'Distância'), \n      bg = c('navy', 'darkorange', 'green'))\n\n## Gráfico\nggplot(data = dados_phylosor, aes(x = dis_alt, y = substituicao)) + \n  labs(x = \"Range altitudinal (m)\", \n       y = \"Componente aninhamento da diversidade beta \\n filogenética (Phylosor)\") +\n  geom_point(size = 6, shape = 21, fill = \"darkorange\", alpha = 0.7) +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = lm, se = TRUE, color = \"black\") +\n  theme_bw(base_size = 16)"},{"path":"cap.-14---diversidade-funcional.html","id":"cap.-14---diversidade-funcional","chapter":"Cap. 14 - Diversidade Funcional","heading":"Cap. 14 - Diversidade Funcional","text":"14.1\nUtilize os dados “aviurba” pacote ade4 para testar o efeito de variáveis ambientais na dispersão (FDis) e regularidade funcional (FEve). Utilize modelos lineares (lm) para testar quais variáveis ambientais são mais importantes para dispersão e regularidade funcional. Além disso, faça um boxplot comparando os valores de FDis e FEve entre categorias das variáveis ambientais mais relevantes.Solução:14.2\nUtilize os dados “mafragh” pacote ade4 para teste o efeito da das variáveis “conductivity”, “silt” e “K2O” na diversidade funcional (método de Petchey e Gaston). Utilize modelos lineares (regressão múltipla) para testar relação entre essas variáveis e discuta () qual variável mais importante (se houver) e (b) se conclusões são coerentes tendo como base os pressupostos dos modelos lineares. Além disso, caso exista alguma relação significativa, faça um gráfico (scatterplot) da relação da variável mais importante e diversidade funcional.Solução:14.3 Utilize os dados “mafragh” pacote ade4 para comparar composição filogenética e funcional em áreas com alta e baixa concentração de potássio. Para fazer esta comparação, será necessário transformar matriz de atributos funcionais e árvore filogenética em matrizes de distância e, depois, utilizar o CWM para criar uma matriz de localidades por composição funcional ou filogenética. Depois, você poderá usar matriz CWM para testar potenciais diferenças entre concentrações com PERMANOVA e para visualizar com PCoA.Solução:","code":"\n\n# Pacotes e dados\nlibrary(ade4)\nlibrary(FD)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(ecodados)\nlibrary(gridExtra)\ndata(aviurba)\ncom <- aviurba$fau # matriz de composição de espécies \ntrait <- aviurba$traits # atributos funcionais das espécies\namb <- aviurba$mil # matriz de variáveis ambientais\n\n# 1. Cálculo da diversidade funcional: FDis e FEve\n\ndiv_fun <- dbFD(trait, com)\n#> Species x species distance matrix was not Euclidean. 'sqrt' correction was applied. \n#> FRic: Only categorical and/or ordinal trait(s) present in 'x'. FRic was measured as the number of unique trait combinations, NOT as the convex hull volume. \n#> FDiv: Cannot be computed when only categorical and/or ordinal trait(s) present in 'x'.\n\nFDis <- div_fun$FDis\nFEve <- div_fun$FEve\n\n\n#. 2. modelos lineares\n\nlm_fdis <- lm(FDis~., data=amb)\nanova(lm_fdis)\n#> Analysis of Variance Table\n#> \n#> Response: FDis\n#>           Df   Sum Sq   Mean Sq F value  Pr(>F)  \n#> farms      1 0.008631 0.0086311  3.1698 0.08422 .\n#> small.bui  1 0.000000 0.0000000  0.0000 0.99665  \n#> high.bui   1 0.001561 0.0015610  0.5733 0.45434  \n#> industry   1 0.012983 0.0129830  4.7680 0.03621 *\n#> fields     1 0.004193 0.0041926  1.5397 0.22341  \n#> grassland  1 0.000053 0.0000528  0.0194 0.89007  \n#> scrubby    1 0.000773 0.0007733  0.2840 0.59767  \n#> deciduous  1 0.000385 0.0003845  0.1412 0.70948  \n#> conifer    1 0.000191 0.0001905  0.0700 0.79304  \n#> noisy      1 0.000386 0.0003859  0.1417 0.70900  \n#> veg.cover  7 0.020059 0.0028655  1.0524 0.41507  \n#> Residuals 33 0.089857 0.0027230                  \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlm_feve <- lm(FEve~., data=amb)\nanova(lm_feve)\n#> Analysis of Variance Table\n#> \n#> Response: FEve\n#>           Df  Sum Sq  Mean Sq F value   Pr(>F)   \n#> farms      1 0.00001 0.000007  0.0005 0.981844   \n#> small.bui  1 0.14651 0.146507 10.7662 0.002446 **\n#> high.bui   1 0.00969 0.009687  0.7118 0.404906   \n#> industry   1 0.00786 0.007860  0.5776 0.452664   \n#> fields     1 0.03908 0.039083  2.8720 0.099549 . \n#> grassland  1 0.00769 0.007686  0.5648 0.457668   \n#> scrubby    1 0.02200 0.021996  1.6164 0.212489   \n#> deciduous  1 0.00010 0.000104  0.0076 0.930976   \n#> conifer    1 0.00192 0.001921  0.1412 0.709495   \n#> noisy      1 0.04924 0.049236  3.6181 0.065911 . \n#> veg.cover  7 0.14969 0.021385  1.5715 0.178578   \n#> Residuals 33 0.44907 0.013608                    \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n# 3. Para facilitar a construção dos gráficos, podemos criar um data.frame\n\ndat_graf <- data.frame(amb, FDis, FEve)\n\n# 4. Gráficos\n\ndat_graf %>% \n  ggplot(aes(x = industry, y = FDis, fill = industry)) +\n  geom_boxplot(width = 0.4, alpha = 0.7)+\n  scale_fill_manual(values = c(\"cyan4\", \"darkorange\"))+\n  labs(x = \"Presença de indústrias\", y = \"Divergência Funcional (FDis)\") +\n  tema_livro() -> g_fdis\n\ndat_graf %>% \n  ggplot(aes(x = small.bui, y = FDis, fill = small.bui)) +\n  geom_boxplot(width = 0.4, alpha = 0.7)+\n  scale_fill_manual(values = c(\"cyan4\", \"darkorange\"))+\n  labs(x = \"Presença de pequenas construções\", y = \"Regularidade Funcional (FEve)\") +\n  tema_livro() -> g_feve\n\ngrid.arrange(g_fdis, g_feve, nrow = 1)\n\n# Pacotes e dados\nlibrary(ade4)\nlibrary(vegan)\nlibrary(ape)\nlibrary(picante)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(ecodados)\n\n\ndata(mafragh)\ntrait_ma <- mafragh$traits$tabQuantitative  # atributos funcionais das espécies\namb_ma <- mafragh$env # matriz de variáveis ambientais\ncom_ma <- mafragh$flo # matriz de composição de espécies\nnames(com_ma) <- rownames(trait_ma)\n\n# 1. Cálculo da distância funcional\n\ndis <- vegdist(trait_ma, \"euclidean\")\n  \n# 2. Construção do dendrograma  \n\ndendro_ma <- hclust(dis, \"average\")\n\n# 3. Transformar dendrograma em classe phylo  \n\ntree_ma<- as.phylo(dendro_ma)\n\n# 4. Diversidade Funcional de Petchey & Gaston\n\nFD_ma <- pd(com_ma, tree_ma)$PD\n\n#. 5. modelo linear\n\nlm_FD <- lm(FD_ma~Conductivity+`K+`+Silt+K2O, data=amb_ma)\npar(mfrow = c(2, 2), oma = c(0, 0, 2, 0))\nplot(lm_FD)\n\nanova(lm_FD) # resultados\n#> Analysis of Variance Table\n#> \n#> Response: FD_ma\n#>              Df  Sum Sq Mean Sq F value   Pr(>F)    \n#> Conductivity  1   2.104   2.104  1.4431   0.2327    \n#> `K+`          1  35.301  35.301 24.2172 3.76e-06 ***\n#> Silt          1   0.232   0.232  0.1592   0.6909    \n#> K2O           1   0.015   0.015  0.0104   0.9189    \n#> Residuals    92 134.108   1.458                     \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# 6. Para facilitar a construção dos gráficos, adicionar FD no data.frame amb_ma\n\namb_ma$FD <- FD_ma\n\n# 7. Gráfico\n\namb_ma %>% \n  ggplot(aes(x = `K+`, y = FD_ma)) +\n  geom_point(pch = 21, color = \"black\", fill = \"cyan4\", size = 3)+\n  geom_smooth(method = \"lm\", color = \"black\") +\n  labs(x = \"Quantidade de K+\", y = \"Diversidade Funcional (FD)\") +\n  tema_livro() \n\n# Pacotes e dados\nlibrary(ade4)\nlibrary(FD)\nlibrary(vegan)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(ecodados)\n\n\ndata(mafragh)\ntrait_ma <- mafragh$traits$tabQuantitative  # atributos funcionais das espécies\namb_ma <- mafragh$env # matriz de variáveis ambientais\ncom_ma <- mafragh$flo # matriz de composição de espécies\nnames(com_ma) <- rownames(trait_ma)\n\n# 1. CWM: Cálculo da composição funcional\n\ncwm_fun <-  dbFD(trait_ma, com_ma)$CWM \n#> FEVe: Could not be calculated for communities with <3 functionally singular species. \n#> FDis: Equals 0 in communities with only one functionally singular species. \n#> FRic: To respect s > t, FRic could not be calculated for communities with <3 functionally singular species. \n#> FRic: Dimensionality reduction was required. The last PCoA axis (out of 3 in total) was removed. \n#> FRic: Quality of the reduced-space representation = 0.8976601 \n#> FDiv: Could not be calculated for communities with <3 functionally singular species.\n\n# 2. criar uma variável categórica a partir da quantidade de K+\n\namb_ma$k_cat <- ifelse(amb_ma$`K+` > mean(amb_ma$`K+`), \"alto\", \"baixo\")\n\n# 2. PERMANOVA\n\npermanova_cwm <- adonis(cwm_fun ~ k_cat, data = amb_ma)\n\ndis_cwm <- vegdist(cwm_fun, \"euclidean\")\n\n# 3. Betadisper + gráfico PCoA\n\nbetadisper_cwm <- betadisper(dis_cwm, amb_ma$k_cat)\nplot(betadisper_cwm)"},{"path":"cap.-15---dados-geoespaciais-no-r.html","id":"cap.-15---dados-geoespaciais-no-r","chapter":"Cap. 15 - Dados geoespaciais no R","heading":"Cap. 15 - Dados geoespaciais no R","text":"15.1\nImporte o limite dos estados brasileiros formato sf com o nome br. Para isso, use função ne_states pacote rnaturalearth. Crie um mapa simples cinza utilizando função plot(), selecionando coluna geometry com o operador $ e com os argumentos axes e graticule verdadeiros.Solução:15.2\nDados vetoriais podem ser criados com diversos erros de topologia, e.g., sobreposição de linhas ou polígonos ou buracos. Algumas funções exigem que os objetos vetoriais aos quais são atribuídos esses dados não possuam esses erros para que o algoritmo funcione. Para verificar se há erros, podemos usar função st_is_valid() pacote sf. Há diversas forma de correções desses erros, mas vamos usar uma correção simples R, com função st_make_valid(). Vamos fazer essa correção para o br importado anteriormente e atribuindo ao objeto br_valid. Podemos conferir para saber se há erros e fazer um plot.Solução:15.3\nCrie um objeto RasterLayer vazio chamado ra com reSolução: de 5º (~600 km). Atribua um sistema de referência de coordendas com o código 4326. Atribua valores aleatórios de uma distribuição normal e plote o mesmo.Solução:15.4\nReprojete o limite dos estados brasileiros exercício anterior para o CRS SIRGAS 2000/Brazil Polyconic, utilizando o código EPSG:5880 e chamando de br_poly. Faça um mapa simples como exercício 1. Atente para curvaturas das linhas.Solução:15.5\nUtilizando função st_centroid pacote sf, crie um vetor chamado br_valid_cen que armazenará o centroide de cada estado brasileiro objeto br_valid exercício 2 e plot o resultado.Solução:15.6\nAjuste o limite e máscara objeto raster criado exercício 3 para o limite Brasil, atribuindo ao objeto ra_br. Depois reprojete esse raster para mesma projeção utilizada exercício 4 com o nome ra_br_poly e plote o mapa resultante.Solução:15.7\nExtraia os valores de cada pixel raster criado exercício 6 para os centroides dos estados Brasil criado exercício 5, atribuindo à coluna val objeto espacial chamado br_valid_poly_cent_ra.Solução:15.8\nCrie um mapa final usando os resultados dos exercícios 4, 5 e 6. Utilize o pacote tmap e inclua todos os principais elementos de um mapa.Solução:","code":"\nlibrary(rnaturalearth)\nbr <- rnaturalearth::ne_states(country = \"Brazil\", returnclass = \"sf\")\nplot(br$geometry, col = \"gray\", axes = TRUE, graticule = TRUE)\nlibrary(sf)\n\nsf::st_is_valid(br)\n#>  [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n#> [10]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n#> [19]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE\n\nbr_valid <- sf::st_make_valid(br)\nsf::st_is_valid(br_valid)\n#>  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n#> [12] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n#> [23] TRUE TRUE TRUE TRUE TRUE\n\nplot(br_valid$geometry, col = \"gray\", axes = TRUE, graticule = TRUE)\nlibrary(raster)\nra <- raster::raster(res = 5, crs = 4326)\nraster::values(ra) <- rnorm(raster::ncell(ra))\nplot(ra)\nlibrary(sf)\nlibrary(rnaturalearth)\n\nbr_valid_poly <- sf::st_transform(br_valid, crs = 5880)\nplot(br_valid_poly$geometry, col = \"gray\", axes = TRUE, graticule = TRUE)\nlibrary(sf)\nlibrary(rnaturalearth)\n\nbr_valid_poly_cen <- sf::st_centroid(br_valid_poly)\n\nplot(br_valid_poly$geometry, col = \"gray\", axes = TRUE, graticule = TRUE)\nplot(br_valid_poly_cen$geometry, pch = 20, add = TRUE)\nlibrary(raster)\n\nra_br <- ra %>% \n    raster::crop(br_valid) %>% \n    raster::mask(br_valid)\n\nra_br_poly <- raster::projectRaster(ra_br, crs = \"+init=epsg:5880\")\n\nplot(ra_br_poly)\nplot(br_valid_poly$geometry, add = TRUE)\nplot(br_valid_poly_cen$geometry, pch = 20, add = TRUE)\nbr_valid_poly_cent_ra <- br_valid_poly_cen %>% \n    dplyr::mutate(val = raster::extract(ra_br_poly, .))\nhead(br_valid_poly_cent_ra$val)\n#> [1]  1.0238284 -1.0381480 -0.4493325  0.3284137 -0.1762245\n#> [6]  0.7180757\nlibrary(tmap)\n\ntm_shape(ra_br_poly) +\n    tm_raster(title = \"Raster\") +\n    tm_shape(br_valid_poly) +\n    tm_borders() +\n    tm_shape(br_valid_poly_cent_ra) +\n    tm_bubbles(col = \"val\", size = .2, legend.col.show = FALSE) +\n    tm_graticules(lines = FALSE, \n                  labels.format = list(big.mark = \"\"), \n                  labels.rot = c(0, 90),\n                  labels.size = .7) +\n    tm_compass(position = c(\"right\", \"top\"), size = 2) +\n    tm_scale_bar(size = 1) +\n    tm_xlab(\"Longitude\", size = 1) +\n    tm_ylab(\"Latitude\", size = 1) +\n    tm_credits(\"CRS: SIRGAS2000/Policônica\", position = c(.6, .15), size = .6) +\n    tm_credits(\"Fonte: Natural Earth (2022)\", position = c(.6, .12), size = .6) +\n    tm_layout(main.title = \"Estados do Brasil\",\n              main.title.position = c(.1, .95),\n              main.title.size = 1.5,\n              title.fontface = \"bold\",\n              legend.position = c(\"left\", \"bottom\"),\n              legend.title.fontface = \"bold\")"}]
